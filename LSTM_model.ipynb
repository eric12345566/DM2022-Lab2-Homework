{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b559c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 09:32:14.129358: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax, BatchNormalization\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825551c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9308486579562545529\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 19434962944\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9430742986068178013\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:02:00.0, compute capability: 8.6\"\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 09:32:26.391472: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-21 09:32:26.400846: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-21 09:32:26.421917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce RTX 3090 Ti computeCapability: 8.6\n",
      "coreClock: 1.905GHz coreCount: 84 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 938.86GiB/s\n",
      "2022-11-21 09:32:26.422250: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-11-21 09:32:26.434956: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-11-21 09:32:26.435031: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-11-21 09:32:26.438794: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-21 09:32:26.440442: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-21 09:32:26.442527: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-11-21 09:32:26.445411: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-11-21 09:32:26.447810: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-11-21 09:32:26.448576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-11-21 09:32:26.448635: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-11-21 09:32:27.296372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-11-21 09:32:27.296421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-11-21 09:32:27.296432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-11-21 09:32:27.297310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/device:GPU:0 with 18534 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:02:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8524757",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Data into pd dataframe\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "emotion_df = pd.read_csv('emotion.csv')\n",
    "di_df = pd.read_csv('data_identification.csv')\n",
    "sample_sub_df = pd.read_csv('sampleSubmission.csv')\n",
    "tweets_df = pd.read_pickle(\"tweets_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cefa1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ &lt;LH&gt;</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[authentic, LaughOutLoud]</td>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455558</th>\n",
       "      <td>[NoWonder, Happy]</td>\n",
       "      <td>0x321566</td>\n",
       "      <td>I'm SO HAPPY!!! #NoWonder the name of this sho...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455559</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x38959e</td>\n",
       "      <td>In every circumtance I'd like to be thankful t...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455560</th>\n",
       "      <td>[blessyou]</td>\n",
       "      <td>0x2cbca6</td>\n",
       "      <td>there's currently two girls walking around the...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455561</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455562</th>\n",
       "      <td>[Sundayvibes]</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              hashtags  tweet_id  \\\n",
       "0                           [Snapchat]  0x376b20   \n",
       "1        [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "2                                   []  0x1cd5b0   \n",
       "3            [authentic, LaughOutLoud]  0x1d755c   \n",
       "4                                   []  0x2c91a8   \n",
       "...                                ...       ...   \n",
       "1455558              [NoWonder, Happy]  0x321566   \n",
       "1455559                             []  0x38959e   \n",
       "1455560                     [blessyou]  0x2cbca6   \n",
       "1455561                             []  0x24faed   \n",
       "1455562                  [Sundayvibes]  0x34be8c   \n",
       "\n",
       "                                                      text       emotion  \n",
       "0        People who post \"add me on #Snapchat\" must be ...  anticipation  \n",
       "1        @brianklaas As we see, Trump is dangerous to #...       sadness  \n",
       "2                      Now ISSA is stalking Tasha üòÇüòÇüòÇ <LH>          fear  \n",
       "3        @RISKshow @TheKevinAllison Thx for the BEST TI...           joy  \n",
       "4             Still waiting on those supplies Liscus. <LH>  anticipation  \n",
       "...                                                    ...           ...  \n",
       "1455558  I'm SO HAPPY!!! #NoWonder the name of this sho...           joy  \n",
       "1455559  In every circumtance I'd like to be thankful t...           joy  \n",
       "1455560  there's currently two girls walking around the...           joy  \n",
       "1455561  Ah, corporate life, where you can date <LH> us...           joy  \n",
       "1455562             Blessed to be living #Sundayvibes <LH>           joy  \n",
       "\n",
       "[1455563 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data = pd.merge(tweets_df, emotion_df)\n",
    "t_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72fc1552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41563</th>\n",
       "      <td>[RanbirKapoor]</td>\n",
       "      <td>0x2db88f</td>\n",
       "      <td>T834: I don't know why bad things are more hap...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374274</th>\n",
       "      <td>[GameOfThones7, Insecure]</td>\n",
       "      <td>0x2912a4</td>\n",
       "      <td>So I watched yesterday's episode of #GameOfTho...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145835</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x34f07c</td>\n",
       "      <td>What is it with dokkan on Apple I get better p...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440919</th>\n",
       "      <td>[XtraXtraLove, MercyChinwo]</td>\n",
       "      <td>0x376008</td>\n",
       "      <td>Excess love. Your love is kind, Your love is p...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420229</th>\n",
       "      <td>[prochoice, Safe, OnDemandNoApologies, Governm...</td>\n",
       "      <td>0x232989</td>\n",
       "      <td>As fast as #prochoice went from #Safe&amp;Rare to ...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489632</th>\n",
       "      <td>[WOKENWisdom]</td>\n",
       "      <td>0x2cf73c</td>\n",
       "      <td>@MATTHARDYBRAND Can your #WOKENWisdom explain ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912367</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1d4175</td>\n",
       "      <td>PrankInvasion CALLS OUT h3h3Productions |  &lt;LH...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181239</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1f8e7d</td>\n",
       "      <td>@pamera_chen &lt;LH&gt; WIFEYüíó</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602382</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x352a65</td>\n",
       "      <td>We are creatures of habit. Praising &lt;LH&gt; is ha...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879610</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2b1936</td>\n",
       "      <td>Mr.President @realDonaldTrump Nothing in world...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  hashtags  tweet_id  \\\n",
       "41563                                       [RanbirKapoor]  0x2db88f   \n",
       "1374274                          [GameOfThones7, Insecure]  0x2912a4   \n",
       "1145835                                                 []  0x34f07c   \n",
       "440919                         [XtraXtraLove, MercyChinwo]  0x376008   \n",
       "1420229  [prochoice, Safe, OnDemandNoApologies, Governm...  0x232989   \n",
       "...                                                    ...       ...   \n",
       "489632                                       [WOKENWisdom]  0x2cf73c   \n",
       "912367                                                  []  0x1d4175   \n",
       "1181239                                                 []  0x1f8e7d   \n",
       "602382                                                  []  0x352a65   \n",
       "879610                                                  []  0x2b1936   \n",
       "\n",
       "                                                      text       emotion  \n",
       "41563    T834: I don't know why bad things are more hap...           joy  \n",
       "1374274  So I watched yesterday's episode of #GameOfTho...          fear  \n",
       "1145835  What is it with dokkan on Apple I get better p...       disgust  \n",
       "440919   Excess love. Your love is kind, Your love is p...         trust  \n",
       "1420229  As fast as #prochoice went from #Safe&Rare to ...         trust  \n",
       "...                                                    ...           ...  \n",
       "489632   @MATTHARDYBRAND Can your #WOKENWisdom explain ...       sadness  \n",
       "912367   PrankInvasion CALLS OUT h3h3Productions |  <LH...      surprise  \n",
       "1181239                           @pamera_chen <LH> WIFEYüíó           joy  \n",
       "602382   We are creatures of habit. Praising <LH> is ha...  anticipation  \n",
       "879610   Mr.President @realDonaldTrump Nothing in world...  anticipation  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data_sample = t_data.sample(n=100)\n",
    "t_data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcadeef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.2.0/en_core_web_md-3.2.0-py3-none-any.whl (45.7 MB)\n",
      "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45.7/45.7 MB 10.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from en-core-web-md==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.1.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.19.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.28.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.4.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.3)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.8.1)\n",
      "Requirement already satisfied: setuptools in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (65.5.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.4.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (4.64.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2022.9.24)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (5.0.0)\n",
      "Installing collected packages: en-core-web-md\n",
      "  Attempting uninstall: en-core-web-md\n",
      "    Found existing installation: en-core-web-md 3.3.0\n",
      "    Uninstalling en-core-web-md-3.3.0:\n",
      "      Successfully uninstalled en-core-web-md-3.3.0\n",
      "Successfully installed en-core-web-md-3.2.0\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import spacy.cli\n",
    "\n",
    "spacy.cli.download(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2a26fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md', disable=[\"ner\", \"parser\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bd362a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Apple  --> Apple\n",
      "Word: is  --> be\n",
      "Word: looking  --> look\n",
      "Word: at  --> at\n",
      "Word: buying  --> buy\n",
      "Word: U.K.  --> U.K.\n",
      "Word: startup  --> startup\n",
      "Word: for  --> for\n",
      "Word: $  --> $\n",
      "Word: 1  --> 1\n",
      "Word: billion  --> billion\n"
     ]
    }
   ],
   "source": [
    "for token in  nlp(\"Apple is looking at buying U.K. startup for $1 billion\"):\n",
    "  print('Word: {}  --> {}'.format(token.text, token.lemma_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc4d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"wiki-lemma-100D-phrase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14f108fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Microsoft', 0.8559668660163879),\n",
       " ('Google_Search', 0.8424477577209473),\n",
       " ('Google_Analytics', 0.8412379026412964),\n",
       " ('Yahoo', 0.8326561450958252),\n",
       " ('AltaVista', 0.824895977973938)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('Google', topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74523046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# # Get all words from wiki word2vec model\n",
    "# model_words = set(model.wv.index_to_key)\n",
    "\n",
    "# def text2vec_raw(w2vmodel, text):\n",
    "#     doc = nlp(text)\n",
    "#     # convert a movie review into vectors\n",
    "#     text_vecs = [w2vmodel.wv[word.lemma_] for word in doc if word.lemma_ in model_words]\n",
    "#     # calculate the mean of the vectors and return\n",
    "\n",
    "#     if len(text_vecs) > 1:\n",
    "#         res =  np.mean(text_vecs, axis = 0)\n",
    "#         return res\n",
    "#     elif len(text_vecs) == 1:\n",
    "#         return text_vecs[0]\n",
    "#     else:\n",
    "#         return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e27b4088",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('keras_word2vec.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5398684a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['346848', '100']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "with open('keras_word2vec.txt') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    # Âè™Êé•ÂèóÈï∑Â∫¶ÁÇ∫ 101 ÁöÑÂêëÈáè (word + 100d embedding)\n",
    "    if len(values) != 101:\n",
    "      print(values)\n",
    "      continue\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69f2869a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.2.0/en_core_web_md-3.2.0-py3-none-any.whl (45.7 MB)\n",
      "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 45.7/45.7 MB 4.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from en-core-web-md==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.28.1)\n",
      "Requirement already satisfied: jinja2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.19.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (21.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (4.64.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: setuptools in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (65.5.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.26.12)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (5.0.0)\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 236.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_md\")\n",
    "nlp = spacy.load('en_core_web_md', disable=[\"ner\", \"parser\"])\n",
    "\n",
    "review_lines = list()\n",
    "reviews = t_data_sample['text'].values.tolist()\n",
    "\n",
    "for review in tqdm(reviews):   \n",
    "    doc = nlp(review)\n",
    "    words = [word.lemma_ for word in doc]\n",
    "    review_lines.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "806f7d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "np.save(\"test_review_lines\", review_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c8ccfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review_lines = np.load(\"test_review_lines.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "012efde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['T834',\n",
       "  ':',\n",
       "  'I',\n",
       "  'do',\n",
       "  'not',\n",
       "  'know',\n",
       "  'why',\n",
       "  'bad',\n",
       "  'thing',\n",
       "  'be',\n",
       "  'more',\n",
       "  'happy',\n",
       "  'than',\n",
       "  'good',\n",
       "  'thing',\n",
       "  '.',\n",
       "  'to',\n",
       "  'be',\n",
       "  'happy',\n",
       "  'we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'bad',\n",
       "  'or',\n",
       "  'what',\n",
       "  '?',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'RanbirKapoor',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['so',\n",
       "  'I',\n",
       "  'watch',\n",
       "  'yesterday',\n",
       "  \"'s\",\n",
       "  'episode',\n",
       "  'of',\n",
       "  '#',\n",
       "  'gameofthones7',\n",
       "  'and',\n",
       "  'now',\n",
       "  'I',\n",
       "  'be',\n",
       "  'going',\n",
       "  'to',\n",
       "  'watch',\n",
       "  '#',\n",
       "  'insecure',\n",
       "  '.',\n",
       "  'be',\n",
       "  'back',\n",
       "  'later',\n",
       "  'to',\n",
       "  'share',\n",
       "  'my',\n",
       "  'thought'],\n",
       " ['what',\n",
       "  'be',\n",
       "  'it',\n",
       "  'with',\n",
       "  'dokkan',\n",
       "  'on',\n",
       "  'Apple',\n",
       "  'I',\n",
       "  'get',\n",
       "  'well',\n",
       "  'pull',\n",
       "  'then',\n",
       "  'android',\n",
       "  '...',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['excess',\n",
       "  'love',\n",
       "  '.',\n",
       "  'your',\n",
       "  'love',\n",
       "  'be',\n",
       "  'kind',\n",
       "  ',',\n",
       "  'your',\n",
       "  'love',\n",
       "  'be',\n",
       "  'patient',\n",
       "  '.',\n",
       "  'Jesus',\n",
       "  'you',\n",
       "  'love',\n",
       "  'I',\n",
       "  'too',\n",
       "  '/',\n",
       "  'excessively',\n",
       "  'much',\n",
       "  'oooo',\n",
       "  '......',\n",
       "  '#inspire',\n",
       "  '#',\n",
       "  'xtraxtralove',\n",
       "  '#',\n",
       "  'MercyChinwo'],\n",
       " ['as',\n",
       "  'fast',\n",
       "  'as',\n",
       "  '#',\n",
       "  'prochoice',\n",
       "  'go',\n",
       "  'from',\n",
       "  '#',\n",
       "  'safe&rare',\n",
       "  'to',\n",
       "  '#',\n",
       "  'ondemandnoapologie',\n",
       "  'soon',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  '#',\n",
       "  'GovernmentDecides'],\n",
       " ['73',\n",
       "  'the',\n",
       "  'moment',\n",
       "  'in',\n",
       "  'your',\n",
       "  'life',\n",
       "  'be',\n",
       "  'only',\n",
       "  'once',\n",
       "  '#',\n",
       "  'Life',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'November',\n",
       "  '29',\n",
       "  ',',\n",
       "  '2017',\n",
       "  'at',\n",
       "  '10:00pm'],\n",
       " ['@politico',\n",
       "  'why',\n",
       "  'would',\n",
       "  'not',\n",
       "  'they',\n",
       "  '?',\n",
       "  'there',\n",
       "  'be',\n",
       "  'literally',\n",
       "  'zero',\n",
       "  'consequence',\n",
       "  'to',\n",
       "  'they',\n",
       "  'in',\n",
       "  'do',\n",
       "  'so',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['I',\n",
       "  'would',\n",
       "  'sleep',\n",
       "  'much',\n",
       "  'well',\n",
       "  'with',\n",
       "  'your',\n",
       "  'arm',\n",
       "  'wrap',\n",
       "  'around',\n",
       "  'I',\n",
       "  '‚ù§',\n",
       "  'Ô∏è',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'foreveralone'],\n",
       " ['@the5hvote',\n",
       "  '@FifthHarmony',\n",
       "  'Quatro',\n",
       "  ' ',\n",
       "  'I',\n",
       "  'vote',\n",
       "  'for',\n",
       "  '@FifthHarmony',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'for',\n",
       "  'Song',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Summer',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['just',\n",
       "  'gettin',\n",
       "  'some',\n",
       "  '@dippindot',\n",
       "  'at',\n",
       "  'the',\n",
       "  '@Cardinals',\n",
       "  'game',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'night',\n",
       "  '!',\n",
       "  '@bchao524',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'cf',\n",
       "  '#',\n",
       "  'accessibility',\n",
       "  '#',\n",
       "  'loveislove',\n",
       "  '#',\n",
       "  'baseball'],\n",
       " ['always', '<', 'LH', '>', 'with', 'cool', 'lab', 'partner', 'üò≠'],\n",
       " ['have',\n",
       "  'a',\n",
       "  'perfect',\n",
       "  'Sunday',\n",
       "  'put',\n",
       "  'the',\n",
       "  'Christmas',\n",
       "  'decoration',\n",
       "  'up',\n",
       "  'and',\n",
       "  'listen',\n",
       "  'to',\n",
       "  '@sambaileyreal',\n",
       "  'could',\n",
       "  'not',\n",
       "  'be',\n",
       "  'more',\n",
       "  'perfect',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'xxx'],\n",
       " ['our',\n",
       "  'prayer',\n",
       "  'team',\n",
       "  'will',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'for',\n",
       "  'abt',\n",
       "  '15',\n",
       "  'min',\n",
       "  '@830pedt',\n",
       "  'for',\n",
       "  'those',\n",
       "  'in',\n",
       "  'the',\n",
       "  'path',\n",
       "  'of',\n",
       "  '#',\n",
       "  'Irma',\n",
       "  ',',\n",
       "  'fire',\n",
       "  ',',\n",
       "  '&',\n",
       "  'victim',\n",
       "  'of',\n",
       "  '#',\n",
       "  'Harvey',\n",
       "  '.',\n",
       "  '712.770.4010',\n",
       "  'code',\n",
       "  '52.67.88'],\n",
       " ['oh',\n",
       "  'I',\n",
       "  'find',\n",
       "  'the',\n",
       "  'girl',\n",
       "  'teddy',\n",
       "  'bear',\n",
       "  '@',\n",
       "  'Martin',\n",
       "  'place',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'daffodilday'],\n",
       " ['my',\n",
       "  'family',\n",
       "  'be',\n",
       "  'be',\n",
       "  'much',\n",
       "  'more',\n",
       "  'supportive',\n",
       "  'than',\n",
       "  'I',\n",
       "  'think',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['mood', ':', '#', 'BLESSED', '!', 'üòé', 'üí™', 'üèæ'],\n",
       " ['badi',\n",
       "  'ma',\n",
       "  'birthday',\n",
       "  'celebration',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'birthdaymemorie',\n",
       "  '#',\n",
       "  'brothersisiterlove',\n",
       "  '#',\n",
       "  'mommyslove',\n",
       "  '#',\n",
       "  'blessing',\n",
       "  '#',\n",
       "  'lotsoffun',\n",
       "  '#',\n",
       "  'widfamily',\n",
       "  'üòá',\n",
       "  'üòá',\n",
       "  'üòá',\n",
       "  'üòç',\n",
       "  'üòç'],\n",
       " ['only', '<', 'LH', '>', 'know', 'my', 'struggle'],\n",
       " ['when',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'be',\n",
       "  'in',\n",
       "  'it',\n",
       "  ',',\n",
       "  'there',\n",
       "  'be',\n",
       "  'no',\n",
       "  'limit',\n",
       "  '!'],\n",
       " ['@ebyers59',\n",
       "  '@claytravis',\n",
       "  '@uva',\n",
       "  'so',\n",
       "  '...',\n",
       "  'camping',\n",
       "  '?',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['my',\n",
       "  'wife',\n",
       "  'make',\n",
       "  'the',\n",
       "  '#',\n",
       "  'great10',\n",
       "  'k',\n",
       "  'from',\n",
       "  '@berlinlaeuft',\n",
       "  'under',\n",
       "  '60',\n",
       "  'minute',\n",
       "  '#',\n",
       "  'sooo',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['@clubcarmenxxx',\n",
       "  'you',\n",
       "  're',\n",
       "  'not',\n",
       "  'on',\n",
       "  'their',\n",
       "  'level',\n",
       "  'of',\n",
       "  'thought',\n",
       "  'but',\n",
       "  'it',\n",
       "  'sure',\n",
       "  'be',\n",
       "  'a',\n",
       "  'damn',\n",
       "  'shame',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['bad',\n",
       "  'food',\n",
       "  'choice',\n",
       "  'that',\n",
       "  'be',\n",
       "  'make',\n",
       "  'to',\n",
       "  'minimize',\n",
       "  'the',\n",
       "  'feeling',\n",
       "  'of',\n",
       "  'be',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'will',\n",
       "  'worsen',\n",
       "  'how',\n",
       "  'you',\n",
       "  'feel',\n",
       "  '.',\n",
       "  ' ',\n",
       "  '#',\n",
       "  'makehealthyfoodchoice',\n",
       "  '#',\n",
       "  'healthmatter'],\n",
       " ['I',\n",
       "  '‚Äôm',\n",
       "  'so',\n",
       "  'üí§',\n",
       "  '!',\n",
       "  'another',\n",
       "  'long',\n",
       "  'night',\n",
       "  'at',\n",
       "  'the',\n",
       "  'studio',\n",
       "  '...',\n",
       "  'IÔ∏è',\n",
       "  'just',\n",
       "  'wanna',\n",
       "  'lay',\n",
       "  'in',\n",
       "  'üõè',\n",
       "  '!',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['write',\n",
       "  'easy',\n",
       "  'music',\n",
       "  'be',\n",
       "  'so',\n",
       "  'hard',\n",
       "  '#',\n",
       "  'composing',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'learner'],\n",
       " ['I',\n",
       "  'm',\n",
       "  'so',\n",
       "  'proud',\n",
       "  'of',\n",
       "  'u',\n",
       "  '@neelofa',\n",
       "  '..',\n",
       "  'u',\n",
       "  'such',\n",
       "  'good',\n",
       "  'inspire',\n",
       "  'to',\n",
       "  'all',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'redvelvetdrama',\n",
       "  ' ',\n",
       "  '@NeelofateamMy'],\n",
       " ['@bt_dmb', 'it', 'be', 'truly', 'amazing', '<', 'LH', '>', '‚ù§', 'Ô∏è'],\n",
       " ['@michellekhare',\n",
       "  'who',\n",
       "  'could',\n",
       "  'possibly',\n",
       "  'hate',\n",
       "  'you',\n",
       "  '!',\n",
       "  'üòÆ',\n",
       "  'you',\n",
       "  'be',\n",
       "  'simply',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'üòÄ',\n",
       "  'üòé'],\n",
       " ['Lol',\n",
       "  'buy',\n",
       "  'an',\n",
       "  'old',\n",
       "  'blackberry',\n",
       "  'bold',\n",
       "  'tomorrow',\n",
       "  'because',\n",
       "  'I',\n",
       "  'be',\n",
       "  'that',\n",
       "  'guy',\n",
       "  '..',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'blackberryfordabidness',\n",
       "  '#',\n",
       "  'iphonefordabitche',\n",
       "  '#',\n",
       "  'barberline'],\n",
       " ['it',\n",
       "  'be',\n",
       "  'a',\n",
       "  'new',\n",
       "  'month',\n",
       "  'and',\n",
       "  'I',\n",
       "  'be',\n",
       "  'happy',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['TBH',\n",
       "  ':',\n",
       "  'I',\n",
       "  'see',\n",
       "  'a',\n",
       "  'couple',\n",
       "  'hold',\n",
       "  'hand',\n",
       "  'today',\n",
       "  '...',\n",
       "  '#',\n",
       "  'trigger',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'foreveralone'],\n",
       " ['@merkle1234',\n",
       "  '@joyceduboise',\n",
       "  '@therealroseanne',\n",
       "  'wooo',\n",
       "  'hooo',\n",
       "  'would',\n",
       "  'not',\n",
       "  'have',\n",
       "  'be',\n",
       "  'the',\n",
       "  'same',\n",
       "  'without',\n",
       "  'he',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['@ManUtd',\n",
       "  '@rioferdy5',\n",
       "  'what',\n",
       "  'a',\n",
       "  'brilliant',\n",
       "  'player',\n",
       "  '&',\n",
       "  'person',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['40',\n",
       "  'never',\n",
       "  'give',\n",
       "  'up',\n",
       "  'on',\n",
       "  'your',\n",
       "  '#',\n",
       "  'dream',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'I',\n",
       "  'to',\n",
       "  'make',\n",
       "  'your',\n",
       "  'dream',\n",
       "  'come',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'August',\n",
       "  '15',\n",
       "  ',',\n",
       "  '2017',\n",
       "  'at',\n",
       "  '12:15pm'],\n",
       " ['somebody',\n",
       "  'call',\n",
       "  'I',\n",
       "  'alpha',\n",
       "  '!',\n",
       "  'Waaah',\n",
       "  '!',\n",
       "  'üòà',\n",
       "  'do',\n",
       "  'you',\n",
       "  '/',\n",
       "  'guy',\n",
       "  'really',\n",
       "  'think',\n",
       "  'that',\n",
       "  'I',\n",
       "  'be',\n",
       "  'strong',\n",
       "  'as',\n",
       "  'alpha',\n",
       "  '?',\n",
       "  '#',\n",
       "  'MsAlpha',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'threat',\n",
       "  '#',\n",
       "  'strongwoman'],\n",
       " ['give',\n",
       "  'thank',\n",
       "  'on',\n",
       "  'this',\n",
       "  'beautiful',\n",
       "  'Thursday',\n",
       "  '!',\n",
       "  '!',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['as',\n",
       "  'for',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  ',',\n",
       "  'who',\n",
       "  'tf',\n",
       "  'go',\n",
       "  'to',\n",
       "  'their',\n",
       "  'ex',\n",
       "  'house',\n",
       "  ',',\n",
       "  'on',\n",
       "  'their',\n",
       "  'way',\n",
       "  'out',\n",
       "  ',',\n",
       "  'just',\n",
       "  'turn',\n",
       "  'around',\n",
       "  'and',\n",
       "  'give',\n",
       "  'she',\n",
       "  '13',\n",
       "  'quick',\n",
       "  'pump',\n",
       "  'of',\n",
       "  'pipe',\n",
       "  'and',\n",
       "  'storm',\n",
       "  'out',\n",
       "  '?'],\n",
       " ['@niallofficial',\n",
       "  'what',\n",
       "  'a',\n",
       "  'cute',\n",
       "  '&',\n",
       "  'cool',\n",
       "  'emoji',\n",
       "  'at',\n",
       "  'the',\n",
       "  'same',\n",
       "  'time',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'and',\n",
       "  'NIALL',\n",
       "  'TOMORROW',\n",
       "  'be',\n",
       "  '20',\n",
       "  'OMG',\n",
       "  'üòç',\n",
       "  'üòç',\n",
       "  'üòç',\n",
       "  '#',\n",
       "  'flicker'],\n",
       " ['look',\n",
       "  'at',\n",
       "  'the',\n",
       "  'calendar',\n",
       "  'and',\n",
       "  'damn',\n",
       "  'my',\n",
       "  'birthday',\n",
       "  'only',\n",
       "  '3',\n",
       "  'week',\n",
       "  'away',\n",
       "  '...',\n",
       "  'I',\n",
       "  'swear',\n",
       "  'I',\n",
       "  'be',\n",
       "  'not',\n",
       "  'even',\n",
       "  'all',\n",
       "  'that',\n",
       "  'excited',\n",
       "  'about',\n",
       "  'it',\n",
       "  'anymore',\n",
       "  'üòû',\n",
       "  ' ',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['\"',\n",
       "  'there',\n",
       "  '4',\n",
       "  '#',\n",
       "  'life',\n",
       "  '\"',\n",
       "  'build',\n",
       "  '#',\n",
       "  'trust',\n",
       "  '.',\n",
       "  'Trust',\n",
       "  'lead',\n",
       "  '2',\n",
       "  '#',\n",
       "  'Freedom',\n",
       "  '2',\n",
       "  'b',\n",
       "  'u',\n",
       "  'with',\n",
       "  'someone',\n",
       "  '.',\n",
       "  'Trust',\n",
       "  'must',\n",
       "  'b',\n",
       "  '#',\n",
       "  'earn',\n",
       "  '/',\n",
       "  'carefully',\n",
       "  '#',\n",
       "  'maintain',\n",
       "  'by',\n",
       "  'someone',\n",
       "  '2',\n",
       "  'b',\n",
       "  'real',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'our',\n",
       "  'HEALTH',\n",
       "  'care',\n",
       "  'BURNS',\n",
       "  ',',\n",
       "  'the',\n",
       "  'left',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'stroke',\n",
       "  'themselves',\n",
       "  'with',\n",
       "  'this',\n",
       "  'monumental',\n",
       "  'russian',\n",
       "  'BULLSHIT',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'fuggovttakeover'],\n",
       " ['#',\n",
       "  'yoo',\n",
       "  '....',\n",
       "  'its',\n",
       "  'be',\n",
       "  'long',\n",
       "  '#',\n",
       "  'new_shot',\n",
       "  '#',\n",
       "  'frosh_niggs',\n",
       "  '#',\n",
       "  'God',\n",
       "  \"'s\",\n",
       "  'favorite',\n",
       "  '#',\n",
       "  'grace_all_the_way',\n",
       "  '#',\n",
       "  'tayo_louis',\n",
       "  '‚Äî',\n",
       "  'feel',\n",
       "  'bless'],\n",
       " ['hatred',\n",
       "  'can',\n",
       "  'not',\n",
       "  'cure',\n",
       "  'hatred',\n",
       "  ',',\n",
       "  'only',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'can',\n",
       "  '.',\n",
       "  'I',\n",
       "  'still',\n",
       "  'choose',\n",
       "  'to',\n",
       "  'love',\n",
       "  'she',\n",
       "  'and',\n",
       "  'all',\n",
       "  'other',\n",
       "  'here',\n",
       "  '.'],\n",
       " ['watch',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '@mark_wahlberg',\n",
       "  'love',\n",
       "  'ya',\n",
       "  '‚ù§',\n",
       "  'Ô∏èalway',\n",
       "  'have',\n",
       "  'always',\n",
       "  'will',\n",
       "  '....'],\n",
       " ['@underlondonman', 'Rod', 'Hull', 'and', 'Emu', '?', '<', 'LH', '>'],\n",
       " ['never',\n",
       "  'have',\n",
       "  'a',\n",
       "  'problem',\n",
       "  'with',\n",
       "  '@uber',\n",
       "  'before',\n",
       "  ',',\n",
       "  'but',\n",
       "  'after',\n",
       "  'this',\n",
       "  'weekend',\n",
       "  ',',\n",
       "  'I',\n",
       "  'may',\n",
       "  'never',\n",
       "  'use',\n",
       "  'it',\n",
       "  'again',\n",
       "  '!',\n",
       "  '#',\n",
       "  'UberOttawa',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'extortion',\n",
       "  '#',\n",
       "  'stopyellingatme'],\n",
       " ['@realgloriawhite', 'consider', 'yourself', '<', 'LH', '>'],\n",
       " ['the',\n",
       "  'good',\n",
       "  'bday',\n",
       "  'present',\n",
       "  'I',\n",
       "  'get',\n",
       "  'today',\n",
       "  'be',\n",
       "  'when',\n",
       "  'alexa',\n",
       "  'texte',\n",
       "  'I',\n",
       "  'and',\n",
       "  'say',\n",
       "  'she',\n",
       "  'schedule',\n",
       "  'she',\n",
       "  'an',\n",
       "  'eye',\n",
       "  'appointment',\n",
       "  '!',\n",
       "  '!',\n",
       "  '!',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['when',\n",
       "  'your',\n",
       "  'good',\n",
       "  'friend',\n",
       "  'help',\n",
       "  'you',\n",
       "  'get',\n",
       "  'your',\n",
       "  'goal',\n",
       "  'on',\n",
       "  'point',\n",
       "  ',',\n",
       "  'with',\n",
       "  'a',\n",
       "  'fool',\n",
       "  'proof',\n",
       "  'plan',\n",
       "  ',',\n",
       "  'and',\n",
       "  'do',\n",
       "  'it',\n",
       "  'because',\n",
       "  'she',\n",
       "  'want',\n",
       "  'to',\n",
       "  'see',\n",
       "  'you',\n",
       "  'happy',\n",
       "  'üòç',\n",
       "  'üòò',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['@leatherjuicebox', 'there', '‚Äô', 'an', 'assistant', 'lol', '<', 'LH', '>'],\n",
       " ['@BeautyRetweetz',\n",
       "  'thank',\n",
       "  'u',\n",
       "  'for',\n",
       "  'that',\n",
       "  ':D',\n",
       "  'feeling',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'now',\n",
       "  ':D',\n",
       "  'have',\n",
       "  'an',\n",
       "  'awesome',\n",
       "  'weekend',\n",
       "  '@beautyretweetz',\n",
       "  ' ',\n",
       "  '^___^'],\n",
       " ['if',\n",
       "  'you',\n",
       "  '#',\n",
       "  'thank',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'for',\n",
       "  'your',\n",
       "  'food',\n",
       "  'and',\n",
       "  'not',\n",
       "  'your',\n",
       "  '#',\n",
       "  'medicine',\n",
       "  ',',\n",
       "  'maybe',\n",
       "  'you',\n",
       "  'ought',\n",
       "  'to',\n",
       "  'rethink',\n",
       "  'your',\n",
       "  '#',\n",
       "  'blessing',\n",
       "  '.'],\n",
       " ['thank',\n",
       "  'you',\n",
       "  '@Delta',\n",
       "  'for',\n",
       "  'the',\n",
       "  'four',\n",
       "  'hour',\n",
       "  'delay',\n",
       "  'this',\n",
       "  'morning',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'I',\n",
       "  'have',\n",
       "  'no',\n",
       "  'interest',\n",
       "  'in',\n",
       "  'get',\n",
       "  'up',\n",
       "  'at',\n",
       "  '4',\n",
       "  'am',\n",
       "  'for',\n",
       "  'the',\n",
       "  '6',\n",
       "  'am',\n",
       "  'flight',\n",
       "  '.',\n",
       "  ' ',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['@jendeuk854',\n",
       "  'eggplant',\n",
       "  'üçÜ',\n",
       "  'jendeuk',\n",
       "  ',',\n",
       "  'JOY',\n",
       "  'calling',\n",
       "  'for',\n",
       "  'ROS√â',\n",
       "  'let',\n",
       "  'I',\n",
       "  'die',\n",
       "  'in',\n",
       "  'PEACE',\n",
       "  '  ',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'blackpink',\n",
       "  '#',\n",
       "  'Ros√©',\n",
       "  'TV',\n",
       "  ',',\n",
       "  'thuesday',\n",
       "  ',',\n",
       "  'Paul',\n",
       "  ':)',\n",
       "  'TRAIN',\n",
       "  '?'],\n",
       " ['I',\n",
       "  'just',\n",
       "  'buy',\n",
       "  'another',\n",
       "  'Xbox',\n",
       "  'One',\n",
       "  'so',\n",
       "  'I',\n",
       "  'could',\n",
       "  'play',\n",
       "  '@friday13thgame',\n",
       "  'with',\n",
       "  'my',\n",
       "  'son',\n",
       "  '!',\n",
       "  '#',\n",
       "  'addiction',\n",
       "  '#',\n",
       "  'Dizzle',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'killthemalljason'],\n",
       " ['@theseamerican',\n",
       "  '@robdelaney',\n",
       "  'now',\n",
       "  'I',\n",
       "  'can',\n",
       "  'not',\n",
       "  'unsee',\n",
       "  'that',\n",
       "  '!',\n",
       "  'what',\n",
       "  'a',\n",
       "  'way',\n",
       "  'to',\n",
       "  'lose',\n",
       "  'weight!#lost',\n",
       "  'appetite'],\n",
       " ['reactivity',\n",
       "  'be',\n",
       "  'the',\n",
       "  'last',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'influence',\n",
       "  'I',\n",
       "  'need',\n",
       "  'around',\n",
       "  'I',\n",
       "  '.',\n",
       "  'I',\n",
       "  'will',\n",
       "  'live',\n",
       "  'and',\n",
       "  'I',\n",
       "  'let',\n",
       "  'other',\n",
       "  'live',\n",
       "  'too',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'protest',\n",
       "  '#',\n",
       "  'liveandletdie',\n",
       "  '#',\n",
       "  'think'],\n",
       " ['@ivanadabiebs', 'Besh', '<', 'LH', '>', 'üòÇ'],\n",
       " ['@boringenormous',\n",
       "  'do',\n",
       "  'he',\n",
       "  'have',\n",
       "  'a',\n",
       "  '@youtube',\n",
       "  'channel',\n",
       "  '?',\n",
       "  '!',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['#',\n",
       "  'nationalgirlfriendday',\n",
       "  '?',\n",
       "  'you',\n",
       "  'know',\n",
       "  ',',\n",
       "  'I',\n",
       "  'think',\n",
       "  'I',\n",
       "  'be',\n",
       "  'a',\n",
       "  'good',\n",
       "  'girlfriend',\n",
       "  ',',\n",
       "  'but',\n",
       "  'I',\n",
       "  'guess',\n",
       "  'not',\n",
       "  '...',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['we',\n",
       "  'keep',\n",
       "  'donating',\n",
       "  'to',\n",
       "  'Puerto',\n",
       "  'Rico',\n",
       "  'but',\n",
       "  'every',\n",
       "  'time',\n",
       "  'I',\n",
       "  'turn',\n",
       "  'on',\n",
       "  'the',\n",
       "  'news',\n",
       "  'everybody',\n",
       "  'be',\n",
       "  'still',\n",
       "  'in',\n",
       "  'the',\n",
       "  'same',\n",
       "  'position',\n",
       "  '..',\n",
       "  'grrrr',\n",
       "  '!',\n",
       "  '!',\n",
       "  '!',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'donationscam'],\n",
       " ['I',\n",
       "  'just',\n",
       "  'have',\n",
       "  'a',\n",
       "  'lady',\n",
       "  'bug',\n",
       "  'crawl',\n",
       "  'on',\n",
       "  'my',\n",
       "  'hand',\n",
       "  '.',\n",
       "  'üêû',\n",
       "  'üôè',\n",
       "  'üôÜ',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'LadyBug',\n",
       "  '#',\n",
       "  'FeelingLucky'],\n",
       " ['it',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'you',\n",
       "  'just',\n",
       "  'keep',\n",
       "  'on',\n",
       "  'pull',\n",
       "  'I',\n",
       "  'down',\n",
       "  ',',\n",
       "  'sometimes',\n",
       "  'I',\n",
       "  'fall',\n",
       "  'without',\n",
       "  'make',\n",
       "  'a',\n",
       "  'sound',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'tomorrow'],\n",
       " ['serious',\n",
       "  '#',\n",
       "  'question',\n",
       "  ':',\n",
       "  'can',\n",
       "  '#',\n",
       "  'baby',\n",
       "  'hear',\n",
       "  'their',\n",
       "  '#',\n",
       "  'mom',\n",
       "  '#',\n",
       "  'fart',\n",
       "  'when',\n",
       "  'in',\n",
       "  '#',\n",
       "  'utero',\n",
       "  '?',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'someoneanswer'],\n",
       " ['<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'Sunday',\n",
       "  'for',\n",
       "  'my',\n",
       "  'follower',\n",
       "  'n',\n",
       "  'I',\n",
       "  'follow',\n",
       "  'üòç',\n",
       "  'üòç',\n",
       "  'üé∂',\n",
       "  'üé∂',\n",
       "  'üôå',\n",
       "  'üôå',\n",
       "  'üíò',\n",
       "  'üíò',\n",
       "  'üíï',\n",
       "  'üíï',\n",
       "  'üéâ',\n",
       "  'üéâ',\n",
       "  'üåº',\n",
       "  'üåº',\n",
       "  'üíï',\n",
       "  'üíï',\n",
       "  'üíü',\n",
       "  'üíü',\n",
       "  'üéà',\n",
       "  'üéà',\n",
       "  'üòò',\n",
       "  'üòò',\n",
       "  'üòÅ',\n",
       "  'üòÅ',\n",
       "  'üåπ',\n",
       "  'üåπ'],\n",
       " ['@IdasRogue',\n",
       "  'blame',\n",
       "  'it',\n",
       "  'on',\n",
       "  'Jesus',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'also',\n",
       "  'you',\n",
       "  'ready',\n",
       "  'for',\n",
       "  'this',\n",
       "  'game',\n",
       "  'tonight',\n",
       "  'my',\n",
       "  'guy',\n",
       "  '!',\n",
       "  '!',\n",
       "  '!'],\n",
       " ['the',\n",
       "  'Golden',\n",
       "  'Rule',\n",
       "  'be',\n",
       "  'surely',\n",
       "  'golden',\n",
       "  'when',\n",
       "  'our',\n",
       "  '\"',\n",
       "  'do',\n",
       "  'unto',\n",
       "  'other',\n",
       "  '\"',\n",
       "  'be',\n",
       "  'all',\n",
       "  'about',\n",
       "  'do',\n",
       "  'love',\n",
       "  '!',\n",
       "  'let',\n",
       "  'us',\n",
       "  'love',\n",
       "  'on',\n",
       "  'purpose',\n",
       "  '!',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'l'],\n",
       " ['<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'to',\n",
       "  'have',\n",
       "  'these',\n",
       "  'two',\n",
       "  'foot',\n",
       "  '.',\n",
       "  '  ',\n",
       "  'what',\n",
       "  'be',\n",
       "  'you',\n",
       "  'grateful',\n",
       "  'for',\n",
       "  '?'],\n",
       " ['\"',\n",
       "  '#',\n",
       "  'Bravery',\n",
       "  'be',\n",
       "  'the',\n",
       "  'solution',\n",
       "  'to',\n",
       "  '#',\n",
       "  'regret',\n",
       "  '.',\n",
       "  '\"',\n",
       "  ' ',\n",
       "  '-',\n",
       "  '#',\n",
       "  'robinsharma',\n",
       "  ' ',\n",
       "  '#',\n",
       "  'motivationalquote',\n",
       "  '#',\n",
       "  'QOTD',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'mondaymotivation',\n",
       "  '#',\n",
       "  'motivation'],\n",
       " ['the',\n",
       "  'Dinkster',\n",
       "  'want',\n",
       "  'by',\n",
       "  'the',\n",
       "  'FBI',\n",
       "  '!',\n",
       "  '|',\n",
       "  ' ',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  ' ',\n",
       "  'üò≠'],\n",
       " ['<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'hey',\n",
       "  'bby',\n",
       "  '!',\n",
       "  'I',\n",
       "  'love',\n",
       "  'you',\n",
       "  ':)',\n",
       "  'I',\n",
       "  'miss',\n",
       "  'you',\n",
       "  'everyday',\n",
       "  ':)',\n",
       "  '@cyjinriy',\n",
       "  '-ur',\n",
       "  'hubby'],\n",
       " ['@easyjet',\n",
       "  'now',\n",
       "  'an',\n",
       "  'added',\n",
       "  '45',\n",
       "  'minute',\n",
       "  'delay',\n",
       "  'again',\n",
       "  'no',\n",
       "  'information',\n",
       "  'give',\n",
       "  'on',\n",
       "  'cause',\n",
       "  'totally',\n",
       "  'ridiculous',\n",
       "  '#',\n",
       "  'delay',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['\"',\n",
       "  'enjoy',\n",
       "  'your',\n",
       "  'gobble',\n",
       "  'gobble',\n",
       "  'Thanksgiving',\n",
       "  '.',\n",
       "  '\"',\n",
       "  'Thanksgiving',\n",
       "  'truly',\n",
       "  'bring',\n",
       "  'out',\n",
       "  'the',\n",
       "  'good',\n",
       "  'in',\n",
       "  'catcaller',\n",
       "  'today',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['go',\n",
       "  'out',\n",
       "  'to',\n",
       "  'everybody',\n",
       "  'in',\n",
       "  '#',\n",
       "  'Houston',\n",
       "  'keep',\n",
       "  'yall',\n",
       "  'head',\n",
       "  'up',\n",
       "  'it',\n",
       "  'will',\n",
       "  'get',\n",
       "  'well',\n",
       "  '..',\n",
       "  'have',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['silence',\n",
       "  'be',\n",
       "  'golden',\n",
       "  '.',\n",
       "  'unless',\n",
       "  'you',\n",
       "  'have',\n",
       "  'kid',\n",
       "  'then',\n",
       "  'silence',\n",
       "  'be',\n",
       "  'just',\n",
       "  'suspicious',\n",
       "  '.',\n",
       "  '#',\n",
       "  'silence',\n",
       "  '#',\n",
       "  'golden',\n",
       "  '#',\n",
       "  'kid',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'joke'],\n",
       " ['@erinnix71',\n",
       "  'no',\n",
       "  'it',\n",
       "  'would',\n",
       "  'not',\n",
       "  'erase',\n",
       "  'the',\n",
       "  'memory',\n",
       "  'he',\n",
       "  'make',\n",
       "  'since',\n",
       "  'come',\n",
       "  'to',\n",
       "  'pc',\n",
       "  'he',\n",
       "  'would',\n",
       "  'just',\n",
       "  'get',\n",
       "  'back',\n",
       "  'the',\n",
       "  'one',\n",
       "  'he',\n",
       "  'have',\n",
       "  'before',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'JaSam'],\n",
       " ['I',\n",
       "  'be',\n",
       "  'just',\n",
       "  'worried',\n",
       "  'about',\n",
       "  'SUNFLOWERS',\n",
       "  'today',\n",
       "  '.',\n",
       "  'what',\n",
       "  'be',\n",
       "  'they',\n",
       "  'go',\n",
       "  'through',\n",
       "  '?',\n",
       "  '#',\n",
       "  'naptime',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'solareclipse2017'],\n",
       " ['@NiykeeHeaton', '@shopnbk', 'yes', 'mami', 'but', '<', 'LH', '>'],\n",
       " ['@nfl',\n",
       "  '@chief',\n",
       "  '@jeffrichadiha',\n",
       "  'will',\n",
       "  'choke',\n",
       "  'in',\n",
       "  'the',\n",
       "  'playoff',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['@realdonaldtrump',\n",
       "  'WTF',\n",
       "  'be',\n",
       "  'wrong',\n",
       "  'with',\n",
       "  'you',\n",
       "  '?',\n",
       "  ' ',\n",
       "  '#',\n",
       "  'narcissist',\n",
       "  '#',\n",
       "  'PredatorInChief',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  ' ',\n",
       "  'as',\n",
       "  'a',\n",
       "  'spirit',\n",
       "  'in',\n",
       "  'the',\n",
       "  'universe',\n",
       "  ',',\n",
       "  'will',\n",
       "  'be',\n",
       "  'take',\n",
       "  'to',\n",
       "  'special',\n",
       "  'healing',\n",
       "  'hall',\n",
       "  'you',\n",
       "  'learn',\n",
       "  'to',\n",
       "  'love',\n",
       "  'and',\n",
       "  'do',\n",
       "  'not',\n",
       "  'want',\n",
       "  'to',\n",
       "  'return',\n",
       "  'on',\n",
       "  'the',\n",
       "  'earth'],\n",
       " ['enter',\n",
       "  'a',\n",
       "  'new',\n",
       "  'chapter',\n",
       "  'in',\n",
       "  'my',\n",
       "  'life',\n",
       "  'and',\n",
       "  'so',\n",
       "  'far',\n",
       "  'I',\n",
       "  'be',\n",
       "  'love',\n",
       "  'it',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'StickingUpForMyself',\n",
       "  '#',\n",
       "  'lettingmyvoicebeheard'],\n",
       " ['Argh', 'Laurence', 'üò¢', '<', 'LH', '>'],\n",
       " ['@CouncillorBill',\n",
       "  '@qikipedia',\n",
       "  'seriously',\n",
       "  'be',\n",
       "  'this',\n",
       "  'still',\n",
       "  'a',\n",
       "  'thing',\n",
       "  'people',\n",
       "  'be',\n",
       "  'like',\n",
       "  '#',\n",
       "  'shame',\n",
       "  '.'],\n",
       " ['I',\n",
       "  'be',\n",
       "  ' ',\n",
       "  '#',\n",
       "  'Blessed',\n",
       "  '....',\n",
       "  'so',\n",
       "  'why',\n",
       "  'not',\n",
       "  '\"',\n",
       "  'be',\n",
       "  'a',\n",
       "  'blesson',\n",
       "  'to',\n",
       "  'other',\n",
       "  ';',\n",
       "  '#',\n",
       "  'spreadtheblesson',\n",
       "  \"'s\",\n",
       "  '#',\n",
       "  'BlessSumone',\n",
       "  'Today',\n",
       "  '!'],\n",
       " ['<', 'LH', '>', 'birthday#Django', '#', 'happybirthday', 'üéâ', 'üéâ', 'üéâ', 'üéâ'],\n",
       " ['if',\n",
       "  'there',\n",
       "  'be',\n",
       "  '#',\n",
       "  'love',\n",
       "  ',',\n",
       "  'small',\n",
       "  'pox',\n",
       "  'scar',\n",
       "  'be',\n",
       "  'as',\n",
       "  'pretty',\n",
       "  'as',\n",
       "  'dimple',\n",
       "  '.',\n",
       "  '~japanese',\n",
       "  'proverb'],\n",
       " ['Summer2017',\n",
       "  'be',\n",
       "  'to',\n",
       "  '#',\n",
       "  'rejuvenate',\n",
       "  '#',\n",
       "  'introspect',\n",
       "  '#',\n",
       "  'takeiteasy',\n",
       "  '.',\n",
       "  'all',\n",
       "  'this',\n",
       "  'be',\n",
       "  'need',\n",
       "  'to',\n",
       "  'enter',\n",
       "  'in',\n",
       "  'job',\n",
       "  'search',\n",
       "  'process',\n",
       "  'with',\n",
       "  'a',\n",
       "  'new',\n",
       "  'perspective',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['@haley_davlin',\n",
       "  '@ColeDrank',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'lol',\n",
       "  '.',\n",
       "  'Kidding',\n",
       "  '.',\n",
       "  'Cole',\n",
       "  'and',\n",
       "  'Kramer',\n",
       "  'the',\n",
       "  'good',\n",
       "  'from',\n",
       "  'LSU'],\n",
       " ['when',\n",
       "  'you',\n",
       "  'be',\n",
       "  'first',\n",
       "  '#',\n",
       "  'effort',\n",
       "  'result',\n",
       "  'from',\n",
       "  '#',\n",
       "  'enjoy',\n",
       "  'your',\n",
       "  ' ',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'freedom',\n",
       "  'be',\n",
       "  'be',\n",
       "  '#',\n",
       "  'spamme',\n",
       "  'by',\n",
       "  '#',\n",
       "  'porn',\n",
       "  '#',\n",
       "  'tumblrbot',\n",
       "  'üòÑ'],\n",
       " ['my',\n",
       "  'head',\n",
       "  'be',\n",
       "  'genuinely',\n",
       "  'sore',\n",
       "  'when',\n",
       "  'I',\n",
       "  'think',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'stuff',\n",
       "  'my',\n",
       "  'wife',\n",
       "  'have',\n",
       "  'to',\n",
       "  'arrange',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'notreally'],\n",
       " ['@dpenn70',\n",
       "  'you',\n",
       "  'talk',\n",
       "  'about',\n",
       "  'your',\n",
       "  'the',\n",
       "  'good',\n",
       "  '.',\n",
       "  'there',\n",
       "  'be',\n",
       "  'several',\n",
       "  'play',\n",
       "  'you',\n",
       "  'get',\n",
       "  'push',\n",
       "  'back',\n",
       "  'WTF',\n",
       "  'man',\n",
       "  'play',\n",
       "  'ball',\n",
       "  'and',\n",
       "  'stop',\n",
       "  'run',\n",
       "  'your',\n",
       "  'mouth',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['@kollelniye',\n",
       "  'r\"l',\n",
       "  '!',\n",
       "  'you',\n",
       "  'hope',\n",
       "  'so',\n",
       "  '?',\n",
       "  '?',\n",
       "  'you',\n",
       "  'become',\n",
       "  'a',\n",
       "  'regular',\n",
       "  'Choivev',\n",
       "  'Tziyoin',\n",
       "  '?',\n",
       "  '?',\n",
       "  'you',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'a',\n",
       "  'pure',\n",
       "  'jewish',\n",
       "  'land',\n",
       "  '?',\n",
       "  '?',\n",
       "  '!',\n",
       "  '?'],\n",
       " ['Good', 'Night', '!', ' ', '#', 'sleep', '#', 'bedroom', '<', 'LH', '>'],\n",
       " ['<', 'LH', '>', '<', 'LH', '>', 'and', '<', 'LH', '>', 'today', '.'],\n",
       " ['@MATTHARDYBRAND',\n",
       "  'can',\n",
       "  'your',\n",
       "  '#',\n",
       "  'wokenwisdom',\n",
       "  'explain',\n",
       "  'why',\n",
       "  'you',\n",
       "  'be',\n",
       "  'obsolete',\n",
       "  'on',\n",
       "  'raw',\n",
       "  'tonight',\n",
       "  '?',\n",
       "  '!',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['prankinvasion',\n",
       "  'call',\n",
       "  'out',\n",
       "  'h3h3Productions',\n",
       "  '|',\n",
       "  ' ',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  ' ',\n",
       "  'üòØ'],\n",
       " ['@pamera_chen', '<', 'LH', '>', 'WIFEY', 'üíó'],\n",
       " ['we',\n",
       "  'be',\n",
       "  'creature',\n",
       "  'of',\n",
       "  'habit',\n",
       "  '.',\n",
       "  'praise',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'be',\n",
       "  'habit',\n",
       "  'form',\n",
       "  '.',\n",
       "  'it',\n",
       "  'be',\n",
       "  'a',\n",
       "  'good',\n",
       "  'thing',\n",
       "  '!'],\n",
       " ['Mr.',\n",
       "  'President',\n",
       "  '@realdonaldtrump',\n",
       "  'nothing',\n",
       "  'in',\n",
       "  'world',\n",
       "  'will',\n",
       "  'happen',\n",
       "  'without',\n",
       "  'GodWilling',\n",
       "  '.',\n",
       "  'so',\n",
       "  'there',\n",
       "  'be',\n",
       "  'reason',\n",
       "  'u',\n",
       "  'elect',\n",
       "  'by',\n",
       "  'Nation',\n",
       "  '.',\n",
       "  'make',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'Proud',\n",
       "  'of',\n",
       "  'you']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "280d53d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['T834',\n",
       "  ':',\n",
       "  'I',\n",
       "  'do',\n",
       "  'not',\n",
       "  'know',\n",
       "  'why',\n",
       "  'bad',\n",
       "  'thing',\n",
       "  'be',\n",
       "  'more',\n",
       "  'happy',\n",
       "  'than',\n",
       "  'good',\n",
       "  'thing',\n",
       "  '.',\n",
       "  'to',\n",
       "  'be',\n",
       "  'happy',\n",
       "  'we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'bad',\n",
       "  'or',\n",
       "  'what',\n",
       "  '?',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'RanbirKapoor',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['so',\n",
       "  'I',\n",
       "  'watch',\n",
       "  'yesterday',\n",
       "  \"'s\",\n",
       "  'episode',\n",
       "  'of',\n",
       "  '#',\n",
       "  'gameofthones7',\n",
       "  'and',\n",
       "  'now',\n",
       "  'I',\n",
       "  'be',\n",
       "  'going',\n",
       "  'to',\n",
       "  'watch',\n",
       "  '#',\n",
       "  'insecure',\n",
       "  '.',\n",
       "  'be',\n",
       "  'back',\n",
       "  'later',\n",
       "  'to',\n",
       "  'share',\n",
       "  'my',\n",
       "  'thought'],\n",
       " ['what',\n",
       "  'be',\n",
       "  'it',\n",
       "  'with',\n",
       "  'dokkan',\n",
       "  'on',\n",
       "  'Apple',\n",
       "  'I',\n",
       "  'get',\n",
       "  'well',\n",
       "  'pull',\n",
       "  'then',\n",
       "  'android',\n",
       "  '...',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['excess',\n",
       "  'love',\n",
       "  '.',\n",
       "  'your',\n",
       "  'love',\n",
       "  'be',\n",
       "  'kind',\n",
       "  ',',\n",
       "  'your',\n",
       "  'love',\n",
       "  'be',\n",
       "  'patient',\n",
       "  '.',\n",
       "  'Jesus',\n",
       "  'you',\n",
       "  'love',\n",
       "  'I',\n",
       "  'too',\n",
       "  '/',\n",
       "  'excessively',\n",
       "  'much',\n",
       "  'oooo',\n",
       "  '......',\n",
       "  '#inspire',\n",
       "  '#',\n",
       "  'xtraxtralove',\n",
       "  '#',\n",
       "  'MercyChinwo'],\n",
       " ['as',\n",
       "  'fast',\n",
       "  'as',\n",
       "  '#',\n",
       "  'prochoice',\n",
       "  'go',\n",
       "  'from',\n",
       "  '#',\n",
       "  'safe&rare',\n",
       "  'to',\n",
       "  '#',\n",
       "  'ondemandnoapologie',\n",
       "  'soon',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  '#',\n",
       "  'GovernmentDecides'],\n",
       " ['73',\n",
       "  'the',\n",
       "  'moment',\n",
       "  'in',\n",
       "  'your',\n",
       "  'life',\n",
       "  'be',\n",
       "  'only',\n",
       "  'once',\n",
       "  '#',\n",
       "  'Life',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'November',\n",
       "  '29',\n",
       "  ',',\n",
       "  '2017',\n",
       "  'at',\n",
       "  '10:00pm'],\n",
       " ['@politico',\n",
       "  'why',\n",
       "  'would',\n",
       "  'not',\n",
       "  'they',\n",
       "  '?',\n",
       "  'there',\n",
       "  'be',\n",
       "  'literally',\n",
       "  'zero',\n",
       "  'consequence',\n",
       "  'to',\n",
       "  'they',\n",
       "  'in',\n",
       "  'do',\n",
       "  'so',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['I',\n",
       "  'would',\n",
       "  'sleep',\n",
       "  'much',\n",
       "  'well',\n",
       "  'with',\n",
       "  'your',\n",
       "  'arm',\n",
       "  'wrap',\n",
       "  'around',\n",
       "  'I',\n",
       "  '‚ù§',\n",
       "  'Ô∏è',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'foreveralone'],\n",
       " ['@the5hvote',\n",
       "  '@FifthHarmony',\n",
       "  'Quatro',\n",
       "  ' ',\n",
       "  'I',\n",
       "  'vote',\n",
       "  'for',\n",
       "  '@FifthHarmony',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'for',\n",
       "  'Song',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Summer',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['just',\n",
       "  'gettin',\n",
       "  'some',\n",
       "  '@dippindot',\n",
       "  'at',\n",
       "  'the',\n",
       "  '@Cardinals',\n",
       "  'game',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'night',\n",
       "  '!',\n",
       "  '@bchao524',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'cf',\n",
       "  '#',\n",
       "  'accessibility',\n",
       "  '#',\n",
       "  'loveislove',\n",
       "  '#',\n",
       "  'baseball'],\n",
       " ['always', '<', 'LH', '>', 'with', 'cool', 'lab', 'partner', 'üò≠'],\n",
       " ['have',\n",
       "  'a',\n",
       "  'perfect',\n",
       "  'Sunday',\n",
       "  'put',\n",
       "  'the',\n",
       "  'Christmas',\n",
       "  'decoration',\n",
       "  'up',\n",
       "  'and',\n",
       "  'listen',\n",
       "  'to',\n",
       "  '@sambaileyreal',\n",
       "  'could',\n",
       "  'not',\n",
       "  'be',\n",
       "  'more',\n",
       "  'perfect',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'xxx'],\n",
       " ['our',\n",
       "  'prayer',\n",
       "  'team',\n",
       "  'will',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'for',\n",
       "  'abt',\n",
       "  '15',\n",
       "  'min',\n",
       "  '@830pedt',\n",
       "  'for',\n",
       "  'those',\n",
       "  'in',\n",
       "  'the',\n",
       "  'path',\n",
       "  'of',\n",
       "  '#',\n",
       "  'Irma',\n",
       "  ',',\n",
       "  'fire',\n",
       "  ',',\n",
       "  '&',\n",
       "  'victim',\n",
       "  'of',\n",
       "  '#',\n",
       "  'Harvey',\n",
       "  '.',\n",
       "  '712.770.4010',\n",
       "  'code',\n",
       "  '52.67.88'],\n",
       " ['oh',\n",
       "  'I',\n",
       "  'find',\n",
       "  'the',\n",
       "  'girl',\n",
       "  'teddy',\n",
       "  'bear',\n",
       "  '@',\n",
       "  'Martin',\n",
       "  'place',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'daffodilday'],\n",
       " ['my',\n",
       "  'family',\n",
       "  'be',\n",
       "  'be',\n",
       "  'much',\n",
       "  'more',\n",
       "  'supportive',\n",
       "  'than',\n",
       "  'I',\n",
       "  'think',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['mood', ':', '#', 'BLESSED', '!', 'üòé', 'üí™', 'üèæ'],\n",
       " ['badi',\n",
       "  'ma',\n",
       "  'birthday',\n",
       "  'celebration',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'birthdaymemorie',\n",
       "  '#',\n",
       "  'brothersisiterlove',\n",
       "  '#',\n",
       "  'mommyslove',\n",
       "  '#',\n",
       "  'blessing',\n",
       "  '#',\n",
       "  'lotsoffun',\n",
       "  '#',\n",
       "  'widfamily',\n",
       "  'üòá',\n",
       "  'üòá',\n",
       "  'üòá',\n",
       "  'üòç',\n",
       "  'üòç'],\n",
       " ['only', '<', 'LH', '>', 'know', 'my', 'struggle'],\n",
       " ['when',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'be',\n",
       "  'in',\n",
       "  'it',\n",
       "  ',',\n",
       "  'there',\n",
       "  'be',\n",
       "  'no',\n",
       "  'limit',\n",
       "  '!'],\n",
       " ['@ebyers59',\n",
       "  '@claytravis',\n",
       "  '@uva',\n",
       "  'so',\n",
       "  '...',\n",
       "  'camping',\n",
       "  '?',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['my',\n",
       "  'wife',\n",
       "  'make',\n",
       "  'the',\n",
       "  '#',\n",
       "  'great10',\n",
       "  'k',\n",
       "  'from',\n",
       "  '@berlinlaeuft',\n",
       "  'under',\n",
       "  '60',\n",
       "  'minute',\n",
       "  '#',\n",
       "  'sooo',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['@clubcarmenxxx',\n",
       "  'you',\n",
       "  're',\n",
       "  'not',\n",
       "  'on',\n",
       "  'their',\n",
       "  'level',\n",
       "  'of',\n",
       "  'thought',\n",
       "  'but',\n",
       "  'it',\n",
       "  'sure',\n",
       "  'be',\n",
       "  'a',\n",
       "  'damn',\n",
       "  'shame',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['bad',\n",
       "  'food',\n",
       "  'choice',\n",
       "  'that',\n",
       "  'be',\n",
       "  'make',\n",
       "  'to',\n",
       "  'minimize',\n",
       "  'the',\n",
       "  'feeling',\n",
       "  'of',\n",
       "  'be',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'will',\n",
       "  'worsen',\n",
       "  'how',\n",
       "  'you',\n",
       "  'feel',\n",
       "  '.',\n",
       "  ' ',\n",
       "  '#',\n",
       "  'makehealthyfoodchoice',\n",
       "  '#',\n",
       "  'healthmatter'],\n",
       " ['I',\n",
       "  '‚Äôm',\n",
       "  'so',\n",
       "  'üí§',\n",
       "  '!',\n",
       "  'another',\n",
       "  'long',\n",
       "  'night',\n",
       "  'at',\n",
       "  'the',\n",
       "  'studio',\n",
       "  '...',\n",
       "  'IÔ∏è',\n",
       "  'just',\n",
       "  'wanna',\n",
       "  'lay',\n",
       "  'in',\n",
       "  'üõè',\n",
       "  '!',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['write',\n",
       "  'easy',\n",
       "  'music',\n",
       "  'be',\n",
       "  'so',\n",
       "  'hard',\n",
       "  '#',\n",
       "  'composing',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'learner'],\n",
       " ['I',\n",
       "  'm',\n",
       "  'so',\n",
       "  'proud',\n",
       "  'of',\n",
       "  'u',\n",
       "  '@neelofa',\n",
       "  '..',\n",
       "  'u',\n",
       "  'such',\n",
       "  'good',\n",
       "  'inspire',\n",
       "  'to',\n",
       "  'all',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'redvelvetdrama',\n",
       "  ' ',\n",
       "  '@NeelofateamMy'],\n",
       " ['@bt_dmb', 'it', 'be', 'truly', 'amazing', '<', 'LH', '>', '‚ù§', 'Ô∏è'],\n",
       " ['@michellekhare',\n",
       "  'who',\n",
       "  'could',\n",
       "  'possibly',\n",
       "  'hate',\n",
       "  'you',\n",
       "  '!',\n",
       "  'üòÆ',\n",
       "  'you',\n",
       "  'be',\n",
       "  'simply',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'üòÄ',\n",
       "  'üòé'],\n",
       " ['Lol',\n",
       "  'buy',\n",
       "  'an',\n",
       "  'old',\n",
       "  'blackberry',\n",
       "  'bold',\n",
       "  'tomorrow',\n",
       "  'because',\n",
       "  'I',\n",
       "  'be',\n",
       "  'that',\n",
       "  'guy',\n",
       "  '..',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'blackberryfordabidness',\n",
       "  '#',\n",
       "  'iphonefordabitche',\n",
       "  '#',\n",
       "  'barberline'],\n",
       " ['it',\n",
       "  'be',\n",
       "  'a',\n",
       "  'new',\n",
       "  'month',\n",
       "  'and',\n",
       "  'I',\n",
       "  'be',\n",
       "  'happy',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['TBH',\n",
       "  ':',\n",
       "  'I',\n",
       "  'see',\n",
       "  'a',\n",
       "  'couple',\n",
       "  'hold',\n",
       "  'hand',\n",
       "  'today',\n",
       "  '...',\n",
       "  '#',\n",
       "  'trigger',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'foreveralone'],\n",
       " ['@merkle1234',\n",
       "  '@joyceduboise',\n",
       "  '@therealroseanne',\n",
       "  'wooo',\n",
       "  'hooo',\n",
       "  'would',\n",
       "  'not',\n",
       "  'have',\n",
       "  'be',\n",
       "  'the',\n",
       "  'same',\n",
       "  'without',\n",
       "  'he',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['@ManUtd',\n",
       "  '@rioferdy5',\n",
       "  'what',\n",
       "  'a',\n",
       "  'brilliant',\n",
       "  'player',\n",
       "  '&',\n",
       "  'person',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['40',\n",
       "  'never',\n",
       "  'give',\n",
       "  'up',\n",
       "  'on',\n",
       "  'your',\n",
       "  '#',\n",
       "  'dream',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'I',\n",
       "  'to',\n",
       "  'make',\n",
       "  'your',\n",
       "  'dream',\n",
       "  'come',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'August',\n",
       "  '15',\n",
       "  ',',\n",
       "  '2017',\n",
       "  'at',\n",
       "  '12:15pm'],\n",
       " ['somebody',\n",
       "  'call',\n",
       "  'I',\n",
       "  'alpha',\n",
       "  '!',\n",
       "  'Waaah',\n",
       "  '!',\n",
       "  'üòà',\n",
       "  'do',\n",
       "  'you',\n",
       "  '/',\n",
       "  'guy',\n",
       "  'really',\n",
       "  'think',\n",
       "  'that',\n",
       "  'I',\n",
       "  'be',\n",
       "  'strong',\n",
       "  'as',\n",
       "  'alpha',\n",
       "  '?',\n",
       "  '#',\n",
       "  'MsAlpha',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'threat',\n",
       "  '#',\n",
       "  'strongwoman'],\n",
       " ['give',\n",
       "  'thank',\n",
       "  'on',\n",
       "  'this',\n",
       "  'beautiful',\n",
       "  'Thursday',\n",
       "  '!',\n",
       "  '!',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['as',\n",
       "  'for',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  ',',\n",
       "  'who',\n",
       "  'tf',\n",
       "  'go',\n",
       "  'to',\n",
       "  'their',\n",
       "  'ex',\n",
       "  'house',\n",
       "  ',',\n",
       "  'on',\n",
       "  'their',\n",
       "  'way',\n",
       "  'out',\n",
       "  ',',\n",
       "  'just',\n",
       "  'turn',\n",
       "  'around',\n",
       "  'and',\n",
       "  'give',\n",
       "  'she',\n",
       "  '13',\n",
       "  'quick',\n",
       "  'pump',\n",
       "  'of',\n",
       "  'pipe',\n",
       "  'and',\n",
       "  'storm',\n",
       "  'out',\n",
       "  '?'],\n",
       " ['@niallofficial',\n",
       "  'what',\n",
       "  'a',\n",
       "  'cute',\n",
       "  '&',\n",
       "  'cool',\n",
       "  'emoji',\n",
       "  'at',\n",
       "  'the',\n",
       "  'same',\n",
       "  'time',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'and',\n",
       "  'NIALL',\n",
       "  'TOMORROW',\n",
       "  'be',\n",
       "  '20',\n",
       "  'OMG',\n",
       "  'üòç',\n",
       "  'üòç',\n",
       "  'üòç',\n",
       "  '#',\n",
       "  'flicker'],\n",
       " ['look',\n",
       "  'at',\n",
       "  'the',\n",
       "  'calendar',\n",
       "  'and',\n",
       "  'damn',\n",
       "  'my',\n",
       "  'birthday',\n",
       "  'only',\n",
       "  '3',\n",
       "  'week',\n",
       "  'away',\n",
       "  '...',\n",
       "  'I',\n",
       "  'swear',\n",
       "  'I',\n",
       "  'be',\n",
       "  'not',\n",
       "  'even',\n",
       "  'all',\n",
       "  'that',\n",
       "  'excited',\n",
       "  'about',\n",
       "  'it',\n",
       "  'anymore',\n",
       "  'üòû',\n",
       "  ' ',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['\"',\n",
       "  'there',\n",
       "  '4',\n",
       "  '#',\n",
       "  'life',\n",
       "  '\"',\n",
       "  'build',\n",
       "  '#',\n",
       "  'trust',\n",
       "  '.',\n",
       "  'Trust',\n",
       "  'lead',\n",
       "  '2',\n",
       "  '#',\n",
       "  'Freedom',\n",
       "  '2',\n",
       "  'b',\n",
       "  'u',\n",
       "  'with',\n",
       "  'someone',\n",
       "  '.',\n",
       "  'Trust',\n",
       "  'must',\n",
       "  'b',\n",
       "  '#',\n",
       "  'earn',\n",
       "  '/',\n",
       "  'carefully',\n",
       "  '#',\n",
       "  'maintain',\n",
       "  'by',\n",
       "  'someone',\n",
       "  '2',\n",
       "  'b',\n",
       "  'real',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'our',\n",
       "  'HEALTH',\n",
       "  'care',\n",
       "  'BURNS',\n",
       "  ',',\n",
       "  'the',\n",
       "  'left',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'stroke',\n",
       "  'themselves',\n",
       "  'with',\n",
       "  'this',\n",
       "  'monumental',\n",
       "  'russian',\n",
       "  'BULLSHIT',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'fuggovttakeover'],\n",
       " ['#',\n",
       "  'yoo',\n",
       "  '....',\n",
       "  'its',\n",
       "  'be',\n",
       "  'long',\n",
       "  '#',\n",
       "  'new_shot',\n",
       "  '#',\n",
       "  'frosh_niggs',\n",
       "  '#',\n",
       "  'God',\n",
       "  \"'s\",\n",
       "  'favorite',\n",
       "  '#',\n",
       "  'grace_all_the_way',\n",
       "  '#',\n",
       "  'tayo_louis',\n",
       "  '‚Äî',\n",
       "  'feel',\n",
       "  'bless'],\n",
       " ['hatred',\n",
       "  'can',\n",
       "  'not',\n",
       "  'cure',\n",
       "  'hatred',\n",
       "  ',',\n",
       "  'only',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'can',\n",
       "  '.',\n",
       "  'I',\n",
       "  'still',\n",
       "  'choose',\n",
       "  'to',\n",
       "  'love',\n",
       "  'she',\n",
       "  'and',\n",
       "  'all',\n",
       "  'other',\n",
       "  'here',\n",
       "  '.'],\n",
       " ['watch',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '@mark_wahlberg',\n",
       "  'love',\n",
       "  'ya',\n",
       "  '‚ù§',\n",
       "  'Ô∏èalway',\n",
       "  'have',\n",
       "  'always',\n",
       "  'will',\n",
       "  '....'],\n",
       " ['@underlondonman', 'Rod', 'Hull', 'and', 'Emu', '?', '<', 'LH', '>'],\n",
       " ['never',\n",
       "  'have',\n",
       "  'a',\n",
       "  'problem',\n",
       "  'with',\n",
       "  '@uber',\n",
       "  'before',\n",
       "  ',',\n",
       "  'but',\n",
       "  'after',\n",
       "  'this',\n",
       "  'weekend',\n",
       "  ',',\n",
       "  'I',\n",
       "  'may',\n",
       "  'never',\n",
       "  'use',\n",
       "  'it',\n",
       "  'again',\n",
       "  '!',\n",
       "  '#',\n",
       "  'UberOttawa',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'extortion',\n",
       "  '#',\n",
       "  'stopyellingatme'],\n",
       " ['@realgloriawhite', 'consider', 'yourself', '<', 'LH', '>'],\n",
       " ['the',\n",
       "  'good',\n",
       "  'bday',\n",
       "  'present',\n",
       "  'I',\n",
       "  'get',\n",
       "  'today',\n",
       "  'be',\n",
       "  'when',\n",
       "  'alexa',\n",
       "  'texte',\n",
       "  'I',\n",
       "  'and',\n",
       "  'say',\n",
       "  'she',\n",
       "  'schedule',\n",
       "  'she',\n",
       "  'an',\n",
       "  'eye',\n",
       "  'appointment',\n",
       "  '!',\n",
       "  '!',\n",
       "  '!',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['when',\n",
       "  'your',\n",
       "  'good',\n",
       "  'friend',\n",
       "  'help',\n",
       "  'you',\n",
       "  'get',\n",
       "  'your',\n",
       "  'goal',\n",
       "  'on',\n",
       "  'point',\n",
       "  ',',\n",
       "  'with',\n",
       "  'a',\n",
       "  'fool',\n",
       "  'proof',\n",
       "  'plan',\n",
       "  ',',\n",
       "  'and',\n",
       "  'do',\n",
       "  'it',\n",
       "  'because',\n",
       "  'she',\n",
       "  'want',\n",
       "  'to',\n",
       "  'see',\n",
       "  'you',\n",
       "  'happy',\n",
       "  'üòç',\n",
       "  'üòò',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['@leatherjuicebox', 'there', '‚Äô', 'an', 'assistant', 'lol', '<', 'LH', '>'],\n",
       " ['@BeautyRetweetz',\n",
       "  'thank',\n",
       "  'u',\n",
       "  'for',\n",
       "  'that',\n",
       "  ':D',\n",
       "  'feeling',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'now',\n",
       "  ':D',\n",
       "  'have',\n",
       "  'an',\n",
       "  'awesome',\n",
       "  'weekend',\n",
       "  '@beautyretweetz',\n",
       "  ' ',\n",
       "  '^___^'],\n",
       " ['if',\n",
       "  'you',\n",
       "  '#',\n",
       "  'thank',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'for',\n",
       "  'your',\n",
       "  'food',\n",
       "  'and',\n",
       "  'not',\n",
       "  'your',\n",
       "  '#',\n",
       "  'medicine',\n",
       "  ',',\n",
       "  'maybe',\n",
       "  'you',\n",
       "  'ought',\n",
       "  'to',\n",
       "  'rethink',\n",
       "  'your',\n",
       "  '#',\n",
       "  'blessing',\n",
       "  '.'],\n",
       " ['thank',\n",
       "  'you',\n",
       "  '@Delta',\n",
       "  'for',\n",
       "  'the',\n",
       "  'four',\n",
       "  'hour',\n",
       "  'delay',\n",
       "  'this',\n",
       "  'morning',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'I',\n",
       "  'have',\n",
       "  'no',\n",
       "  'interest',\n",
       "  'in',\n",
       "  'get',\n",
       "  'up',\n",
       "  'at',\n",
       "  '4',\n",
       "  'am',\n",
       "  'for',\n",
       "  'the',\n",
       "  '6',\n",
       "  'am',\n",
       "  'flight',\n",
       "  '.',\n",
       "  ' ',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['@jendeuk854',\n",
       "  'eggplant',\n",
       "  'üçÜ',\n",
       "  'jendeuk',\n",
       "  ',',\n",
       "  'JOY',\n",
       "  'calling',\n",
       "  'for',\n",
       "  'ROS√â',\n",
       "  'let',\n",
       "  'I',\n",
       "  'die',\n",
       "  'in',\n",
       "  'PEACE',\n",
       "  '  ',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'blackpink',\n",
       "  '#',\n",
       "  'Ros√©',\n",
       "  'TV',\n",
       "  ',',\n",
       "  'thuesday',\n",
       "  ',',\n",
       "  'Paul',\n",
       "  ':)',\n",
       "  'TRAIN',\n",
       "  '?'],\n",
       " ['I',\n",
       "  'just',\n",
       "  'buy',\n",
       "  'another',\n",
       "  'Xbox',\n",
       "  'One',\n",
       "  'so',\n",
       "  'I',\n",
       "  'could',\n",
       "  'play',\n",
       "  '@friday13thgame',\n",
       "  'with',\n",
       "  'my',\n",
       "  'son',\n",
       "  '!',\n",
       "  '#',\n",
       "  'addiction',\n",
       "  '#',\n",
       "  'Dizzle',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'killthemalljason'],\n",
       " ['@theseamerican',\n",
       "  '@robdelaney',\n",
       "  'now',\n",
       "  'I',\n",
       "  'can',\n",
       "  'not',\n",
       "  'unsee',\n",
       "  'that',\n",
       "  '!',\n",
       "  'what',\n",
       "  'a',\n",
       "  'way',\n",
       "  'to',\n",
       "  'lose',\n",
       "  'weight!#lost',\n",
       "  'appetite'],\n",
       " ['reactivity',\n",
       "  'be',\n",
       "  'the',\n",
       "  'last',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'influence',\n",
       "  'I',\n",
       "  'need',\n",
       "  'around',\n",
       "  'I',\n",
       "  '.',\n",
       "  'I',\n",
       "  'will',\n",
       "  'live',\n",
       "  'and',\n",
       "  'I',\n",
       "  'let',\n",
       "  'other',\n",
       "  'live',\n",
       "  'too',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'protest',\n",
       "  '#',\n",
       "  'liveandletdie',\n",
       "  '#',\n",
       "  'think'],\n",
       " ['@ivanadabiebs', 'Besh', '<', 'LH', '>', 'üòÇ'],\n",
       " ['@boringenormous',\n",
       "  'do',\n",
       "  'he',\n",
       "  'have',\n",
       "  'a',\n",
       "  '@youtube',\n",
       "  'channel',\n",
       "  '?',\n",
       "  '!',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['#',\n",
       "  'nationalgirlfriendday',\n",
       "  '?',\n",
       "  'you',\n",
       "  'know',\n",
       "  ',',\n",
       "  'I',\n",
       "  'think',\n",
       "  'I',\n",
       "  'be',\n",
       "  'a',\n",
       "  'good',\n",
       "  'girlfriend',\n",
       "  ',',\n",
       "  'but',\n",
       "  'I',\n",
       "  'guess',\n",
       "  'not',\n",
       "  '...',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['we',\n",
       "  'keep',\n",
       "  'donating',\n",
       "  'to',\n",
       "  'Puerto',\n",
       "  'Rico',\n",
       "  'but',\n",
       "  'every',\n",
       "  'time',\n",
       "  'I',\n",
       "  'turn',\n",
       "  'on',\n",
       "  'the',\n",
       "  'news',\n",
       "  'everybody',\n",
       "  'be',\n",
       "  'still',\n",
       "  'in',\n",
       "  'the',\n",
       "  'same',\n",
       "  'position',\n",
       "  '..',\n",
       "  'grrrr',\n",
       "  '!',\n",
       "  '!',\n",
       "  '!',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'donationscam'],\n",
       " ['I',\n",
       "  'just',\n",
       "  'have',\n",
       "  'a',\n",
       "  'lady',\n",
       "  'bug',\n",
       "  'crawl',\n",
       "  'on',\n",
       "  'my',\n",
       "  'hand',\n",
       "  '.',\n",
       "  'üêû',\n",
       "  'üôè',\n",
       "  'üôÜ',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'LadyBug',\n",
       "  '#',\n",
       "  'FeelingLucky'],\n",
       " ['it',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'you',\n",
       "  'just',\n",
       "  'keep',\n",
       "  'on',\n",
       "  'pull',\n",
       "  'I',\n",
       "  'down',\n",
       "  ',',\n",
       "  'sometimes',\n",
       "  'I',\n",
       "  'fall',\n",
       "  'without',\n",
       "  'make',\n",
       "  'a',\n",
       "  'sound',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'tomorrow'],\n",
       " ['serious',\n",
       "  '#',\n",
       "  'question',\n",
       "  ':',\n",
       "  'can',\n",
       "  '#',\n",
       "  'baby',\n",
       "  'hear',\n",
       "  'their',\n",
       "  '#',\n",
       "  'mom',\n",
       "  '#',\n",
       "  'fart',\n",
       "  'when',\n",
       "  'in',\n",
       "  '#',\n",
       "  'utero',\n",
       "  '?',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'someoneanswer'],\n",
       " ['<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'Sunday',\n",
       "  'for',\n",
       "  'my',\n",
       "  'follower',\n",
       "  'n',\n",
       "  'I',\n",
       "  'follow',\n",
       "  'üòç',\n",
       "  'üòç',\n",
       "  'üé∂',\n",
       "  'üé∂',\n",
       "  'üôå',\n",
       "  'üôå',\n",
       "  'üíò',\n",
       "  'üíò',\n",
       "  'üíï',\n",
       "  'üíï',\n",
       "  'üéâ',\n",
       "  'üéâ',\n",
       "  'üåº',\n",
       "  'üåº',\n",
       "  'üíï',\n",
       "  'üíï',\n",
       "  'üíü',\n",
       "  'üíü',\n",
       "  'üéà',\n",
       "  'üéà',\n",
       "  'üòò',\n",
       "  'üòò',\n",
       "  'üòÅ',\n",
       "  'üòÅ',\n",
       "  'üåπ',\n",
       "  'üåπ'],\n",
       " ['@IdasRogue',\n",
       "  'blame',\n",
       "  'it',\n",
       "  'on',\n",
       "  'Jesus',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'also',\n",
       "  'you',\n",
       "  'ready',\n",
       "  'for',\n",
       "  'this',\n",
       "  'game',\n",
       "  'tonight',\n",
       "  'my',\n",
       "  'guy',\n",
       "  '!',\n",
       "  '!',\n",
       "  '!'],\n",
       " ['the',\n",
       "  'Golden',\n",
       "  'Rule',\n",
       "  'be',\n",
       "  'surely',\n",
       "  'golden',\n",
       "  'when',\n",
       "  'our',\n",
       "  '\"',\n",
       "  'do',\n",
       "  'unto',\n",
       "  'other',\n",
       "  '\"',\n",
       "  'be',\n",
       "  'all',\n",
       "  'about',\n",
       "  'do',\n",
       "  'love',\n",
       "  '!',\n",
       "  'let',\n",
       "  'us',\n",
       "  'love',\n",
       "  'on',\n",
       "  'purpose',\n",
       "  '!',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'l'],\n",
       " ['<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'to',\n",
       "  'have',\n",
       "  'these',\n",
       "  'two',\n",
       "  'foot',\n",
       "  '.',\n",
       "  '  ',\n",
       "  'what',\n",
       "  'be',\n",
       "  'you',\n",
       "  'grateful',\n",
       "  'for',\n",
       "  '?'],\n",
       " ['\"',\n",
       "  '#',\n",
       "  'Bravery',\n",
       "  'be',\n",
       "  'the',\n",
       "  'solution',\n",
       "  'to',\n",
       "  '#',\n",
       "  'regret',\n",
       "  '.',\n",
       "  '\"',\n",
       "  ' ',\n",
       "  '-',\n",
       "  '#',\n",
       "  'robinsharma',\n",
       "  ' ',\n",
       "  '#',\n",
       "  'motivationalquote',\n",
       "  '#',\n",
       "  'QOTD',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'mondaymotivation',\n",
       "  '#',\n",
       "  'motivation'],\n",
       " ['the',\n",
       "  'Dinkster',\n",
       "  'want',\n",
       "  'by',\n",
       "  'the',\n",
       "  'FBI',\n",
       "  '!',\n",
       "  '|',\n",
       "  ' ',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  ' ',\n",
       "  'üò≠'],\n",
       " ['<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'hey',\n",
       "  'bby',\n",
       "  '!',\n",
       "  'I',\n",
       "  'love',\n",
       "  'you',\n",
       "  ':)',\n",
       "  'I',\n",
       "  'miss',\n",
       "  'you',\n",
       "  'everyday',\n",
       "  ':)',\n",
       "  '@cyjinriy',\n",
       "  '-ur',\n",
       "  'hubby'],\n",
       " ['@easyjet',\n",
       "  'now',\n",
       "  'an',\n",
       "  'added',\n",
       "  '45',\n",
       "  'minute',\n",
       "  'delay',\n",
       "  'again',\n",
       "  'no',\n",
       "  'information',\n",
       "  'give',\n",
       "  'on',\n",
       "  'cause',\n",
       "  'totally',\n",
       "  'ridiculous',\n",
       "  '#',\n",
       "  'delay',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['\"',\n",
       "  'enjoy',\n",
       "  'your',\n",
       "  'gobble',\n",
       "  'gobble',\n",
       "  'Thanksgiving',\n",
       "  '.',\n",
       "  '\"',\n",
       "  'Thanksgiving',\n",
       "  'truly',\n",
       "  'bring',\n",
       "  'out',\n",
       "  'the',\n",
       "  'good',\n",
       "  'in',\n",
       "  'catcaller',\n",
       "  'today',\n",
       "  '.',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['go',\n",
       "  'out',\n",
       "  'to',\n",
       "  'everybody',\n",
       "  'in',\n",
       "  '#',\n",
       "  'Houston',\n",
       "  'keep',\n",
       "  'yall',\n",
       "  'head',\n",
       "  'up',\n",
       "  'it',\n",
       "  'will',\n",
       "  'get',\n",
       "  'well',\n",
       "  '..',\n",
       "  'have',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['silence',\n",
       "  'be',\n",
       "  'golden',\n",
       "  '.',\n",
       "  'unless',\n",
       "  'you',\n",
       "  'have',\n",
       "  'kid',\n",
       "  'then',\n",
       "  'silence',\n",
       "  'be',\n",
       "  'just',\n",
       "  'suspicious',\n",
       "  '.',\n",
       "  '#',\n",
       "  'silence',\n",
       "  '#',\n",
       "  'golden',\n",
       "  '#',\n",
       "  'kid',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'joke'],\n",
       " ['@erinnix71',\n",
       "  'no',\n",
       "  'it',\n",
       "  'would',\n",
       "  'not',\n",
       "  'erase',\n",
       "  'the',\n",
       "  'memory',\n",
       "  'he',\n",
       "  'make',\n",
       "  'since',\n",
       "  'come',\n",
       "  'to',\n",
       "  'pc',\n",
       "  'he',\n",
       "  'would',\n",
       "  'just',\n",
       "  'get',\n",
       "  'back',\n",
       "  'the',\n",
       "  'one',\n",
       "  'he',\n",
       "  'have',\n",
       "  'before',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'JaSam'],\n",
       " ['I',\n",
       "  'be',\n",
       "  'just',\n",
       "  'worried',\n",
       "  'about',\n",
       "  'SUNFLOWERS',\n",
       "  'today',\n",
       "  '.',\n",
       "  'what',\n",
       "  'be',\n",
       "  'they',\n",
       "  'go',\n",
       "  'through',\n",
       "  '?',\n",
       "  '#',\n",
       "  'naptime',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'solareclipse2017'],\n",
       " ['@NiykeeHeaton', '@shopnbk', 'yes', 'mami', 'but', '<', 'LH', '>'],\n",
       " ['@nfl',\n",
       "  '@chief',\n",
       "  '@jeffrichadiha',\n",
       "  'will',\n",
       "  'choke',\n",
       "  'in',\n",
       "  'the',\n",
       "  'playoff',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['@realdonaldtrump',\n",
       "  'WTF',\n",
       "  'be',\n",
       "  'wrong',\n",
       "  'with',\n",
       "  'you',\n",
       "  '?',\n",
       "  ' ',\n",
       "  '#',\n",
       "  'narcissist',\n",
       "  '#',\n",
       "  'PredatorInChief',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  ' ',\n",
       "  'as',\n",
       "  'a',\n",
       "  'spirit',\n",
       "  'in',\n",
       "  'the',\n",
       "  'universe',\n",
       "  ',',\n",
       "  'will',\n",
       "  'be',\n",
       "  'take',\n",
       "  'to',\n",
       "  'special',\n",
       "  'healing',\n",
       "  'hall',\n",
       "  'you',\n",
       "  'learn',\n",
       "  'to',\n",
       "  'love',\n",
       "  'and',\n",
       "  'do',\n",
       "  'not',\n",
       "  'want',\n",
       "  'to',\n",
       "  'return',\n",
       "  'on',\n",
       "  'the',\n",
       "  'earth'],\n",
       " ['enter',\n",
       "  'a',\n",
       "  'new',\n",
       "  'chapter',\n",
       "  'in',\n",
       "  'my',\n",
       "  'life',\n",
       "  'and',\n",
       "  'so',\n",
       "  'far',\n",
       "  'I',\n",
       "  'be',\n",
       "  'love',\n",
       "  'it',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'StickingUpForMyself',\n",
       "  '#',\n",
       "  'lettingmyvoicebeheard'],\n",
       " ['Argh', 'Laurence', 'üò¢', '<', 'LH', '>'],\n",
       " ['@CouncillorBill',\n",
       "  '@qikipedia',\n",
       "  'seriously',\n",
       "  'be',\n",
       "  'this',\n",
       "  'still',\n",
       "  'a',\n",
       "  'thing',\n",
       "  'people',\n",
       "  'be',\n",
       "  'like',\n",
       "  '#',\n",
       "  'shame',\n",
       "  '.'],\n",
       " ['I',\n",
       "  'be',\n",
       "  ' ',\n",
       "  '#',\n",
       "  'Blessed',\n",
       "  '....',\n",
       "  'so',\n",
       "  'why',\n",
       "  'not',\n",
       "  '\"',\n",
       "  'be',\n",
       "  'a',\n",
       "  'blesson',\n",
       "  'to',\n",
       "  'other',\n",
       "  ';',\n",
       "  '#',\n",
       "  'spreadtheblesson',\n",
       "  \"'s\",\n",
       "  '#',\n",
       "  'BlessSumone',\n",
       "  'Today',\n",
       "  '!'],\n",
       " ['<', 'LH', '>', 'birthday#Django', '#', 'happybirthday', 'üéâ', 'üéâ', 'üéâ', 'üéâ'],\n",
       " ['if',\n",
       "  'there',\n",
       "  'be',\n",
       "  '#',\n",
       "  'love',\n",
       "  ',',\n",
       "  'small',\n",
       "  'pox',\n",
       "  'scar',\n",
       "  'be',\n",
       "  'as',\n",
       "  'pretty',\n",
       "  'as',\n",
       "  'dimple',\n",
       "  '.',\n",
       "  '~japanese',\n",
       "  'proverb'],\n",
       " ['Summer2017',\n",
       "  'be',\n",
       "  'to',\n",
       "  '#',\n",
       "  'rejuvenate',\n",
       "  '#',\n",
       "  'introspect',\n",
       "  '#',\n",
       "  'takeiteasy',\n",
       "  '.',\n",
       "  'all',\n",
       "  'this',\n",
       "  'be',\n",
       "  'need',\n",
       "  'to',\n",
       "  'enter',\n",
       "  'in',\n",
       "  'job',\n",
       "  'search',\n",
       "  'process',\n",
       "  'with',\n",
       "  'a',\n",
       "  'new',\n",
       "  'perspective',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['@haley_davlin',\n",
       "  '@ColeDrank',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'lol',\n",
       "  '.',\n",
       "  'Kidding',\n",
       "  '.',\n",
       "  'Cole',\n",
       "  'and',\n",
       "  'Kramer',\n",
       "  'the',\n",
       "  'good',\n",
       "  'from',\n",
       "  'LSU'],\n",
       " ['when',\n",
       "  'you',\n",
       "  'be',\n",
       "  'first',\n",
       "  '#',\n",
       "  'effort',\n",
       "  'result',\n",
       "  'from',\n",
       "  '#',\n",
       "  'enjoy',\n",
       "  'your',\n",
       "  ' ',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'freedom',\n",
       "  'be',\n",
       "  'be',\n",
       "  '#',\n",
       "  'spamme',\n",
       "  'by',\n",
       "  '#',\n",
       "  'porn',\n",
       "  '#',\n",
       "  'tumblrbot',\n",
       "  'üòÑ'],\n",
       " ['my',\n",
       "  'head',\n",
       "  'be',\n",
       "  'genuinely',\n",
       "  'sore',\n",
       "  'when',\n",
       "  'I',\n",
       "  'think',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'stuff',\n",
       "  'my',\n",
       "  'wife',\n",
       "  'have',\n",
       "  'to',\n",
       "  'arrange',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  '#',\n",
       "  'notreally'],\n",
       " ['@dpenn70',\n",
       "  'you',\n",
       "  'talk',\n",
       "  'about',\n",
       "  'your',\n",
       "  'the',\n",
       "  'good',\n",
       "  '.',\n",
       "  'there',\n",
       "  'be',\n",
       "  'several',\n",
       "  'play',\n",
       "  'you',\n",
       "  'get',\n",
       "  'push',\n",
       "  'back',\n",
       "  'WTF',\n",
       "  'man',\n",
       "  'play',\n",
       "  'ball',\n",
       "  'and',\n",
       "  'stop',\n",
       "  'run',\n",
       "  'your',\n",
       "  'mouth',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['@kollelniye',\n",
       "  'r\"l',\n",
       "  '!',\n",
       "  'you',\n",
       "  'hope',\n",
       "  'so',\n",
       "  '?',\n",
       "  '?',\n",
       "  'you',\n",
       "  'become',\n",
       "  'a',\n",
       "  'regular',\n",
       "  'Choivev',\n",
       "  'Tziyoin',\n",
       "  '?',\n",
       "  '?',\n",
       "  'you',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'a',\n",
       "  'pure',\n",
       "  'jewish',\n",
       "  'land',\n",
       "  '?',\n",
       "  '?',\n",
       "  '!',\n",
       "  '?'],\n",
       " ['Good', 'Night', '!', ' ', '#', 'sleep', '#', 'bedroom', '<', 'LH', '>'],\n",
       " ['<', 'LH', '>', '<', 'LH', '>', 'and', '<', 'LH', '>', 'today', '.'],\n",
       " ['@MATTHARDYBRAND',\n",
       "  'can',\n",
       "  'your',\n",
       "  '#',\n",
       "  'wokenwisdom',\n",
       "  'explain',\n",
       "  'why',\n",
       "  'you',\n",
       "  'be',\n",
       "  'obsolete',\n",
       "  'on',\n",
       "  'raw',\n",
       "  'tonight',\n",
       "  '?',\n",
       "  '!',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>'],\n",
       " ['prankinvasion',\n",
       "  'call',\n",
       "  'out',\n",
       "  'h3h3Productions',\n",
       "  '|',\n",
       "  ' ',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  ' ',\n",
       "  'üòØ'],\n",
       " ['@pamera_chen', '<', 'LH', '>', 'WIFEY', 'üíó'],\n",
       " ['we',\n",
       "  'be',\n",
       "  'creature',\n",
       "  'of',\n",
       "  'habit',\n",
       "  '.',\n",
       "  'praise',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'be',\n",
       "  'habit',\n",
       "  'form',\n",
       "  '.',\n",
       "  'it',\n",
       "  'be',\n",
       "  'a',\n",
       "  'good',\n",
       "  'thing',\n",
       "  '!'],\n",
       " ['Mr.',\n",
       "  'President',\n",
       "  '@realdonaldtrump',\n",
       "  'nothing',\n",
       "  'in',\n",
       "  'world',\n",
       "  'will',\n",
       "  'happen',\n",
       "  'without',\n",
       "  'GodWilling',\n",
       "  '.',\n",
       "  'so',\n",
       "  'there',\n",
       "  'be',\n",
       "  'reason',\n",
       "  'u',\n",
       "  'elect',\n",
       "  'by',\n",
       "  'Nation',\n",
       "  '.',\n",
       "  'make',\n",
       "  '<',\n",
       "  'LH',\n",
       "  '>',\n",
       "  'Proud',\n",
       "  'of',\n",
       "  'you']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_review_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "554917f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'sadness', 'disgust', ..., 'joy', 'anticipation',\n",
       "       'joy'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = t_data_sample['emotion'].values\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df72ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(review_lines, t_data_sample['emotion'],\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.25, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01324210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  75000\n",
      "y_train.shape:  (75000,)\n",
      "x_test.shape:  25000\n",
      "y_test.shape:  (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape: \", len(X_train))\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"x_test.shape: \", len(X_test))\n",
    "print(\"y_test.shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "895456e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  ['anger' 'anticipation' 'disgust' 'fear' 'joy' 'sadness' 'surprise'\n",
      " 'trust']\n",
      "\n",
      "## Before convert\n",
      "y_train[0:4]:\n",
      " ['anticipation' 'sadness' 'disgust' 'sadness']\n",
      "\n",
      "y_train.shape:  (100000,)\n",
      "\n",
      "\n",
      "## After convert\n",
      "y_train[0:4]:\n",
      " [[0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "\n",
      "y_train.shape:  (100000, 8)\n"
     ]
    }
   ],
   "source": [
    "## deal with label (string -> one-hot)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(sentiment)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:4]:\\n', sentiment[0:4])\n",
    "print('\\ny_train.shape: ', sentiment.shape)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return np_utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "sentiment_oh = label_encode(label_encoder, sentiment)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:4]:\\n', sentiment_oh[0:4])\n",
    "print('\\ny_train.shape: ', sentiment_oh.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3dfe64d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimal word count in a movie review:  1\n",
      "The first quantile (25%) of word count in a movie review: 10.0\n",
      "The second quantile (50%) of word count in a movie review: 15.0\n",
      "The third quantile (75%) of word count in a movie review: 20.0\n",
      "The maximum word count in a movie review:  43\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "### ÊâæÂá∫ÂΩ±Ë©ïÂÖ±ÊúâÂπæÂÄã words\n",
    "sentence_lengths = t_data_sample['text'].apply(lambda x: len(x.split()))\n",
    "quantiles = np.percentile(sentence_lengths, [25, 50, 75])\n",
    "\n",
    "print('The minimal word count in a movie review: ', min(sentence_lengths))\n",
    "print('The first quantile (25%) of word count in a movie review:', quantiles[0])\n",
    "print('The second quantile (50%) of word count in a movie review:', quantiles[1])\n",
    "print('The third quantile (75%) of word count in a movie review:', quantiles[2])\n",
    "print('The maximum word count in a movie review: ', max(sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2ff6709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 119720 unique tokens.\n",
      "Shape of review tensor: (100000, 50)\n",
      "Shape of sentiment tensor: (100000, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# ÂàùÂßãÂåñ tokenizer\n",
    "# Â∞áÊñáÂ≠óËΩâÊèõÊàê 2D integer tensor\n",
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(review_lines)\n",
    "sequences = tokenizer_obj.texts_to_sequences(review_lines)\n",
    "\n",
    "# Âõ†ÁÇ∫modelÁöÑinputÂøÖÈ†à‰∏ÄÊ®£Èï∑ÔºåÊâÄ‰ª•Ë¶Å‰ΩøÁî®paddingÔºåÂè•Â≠êÁü≠Êñº512ÁöÑÈÉΩÊúÉË£ú0ÔºåÈï∑Êñº512ÁöÑÊúÉË¢´truncate\n",
    "word_index = tokenizer_obj.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "review_pad = pad_sequences(sequences, maxlen=50)\n",
    "\n",
    "print('Shape of review tensor:', review_pad.shape)\n",
    "print('Shape of sentiment tensor:', sentiment_oh.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1f107501",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in tokenizer_obj.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28ea5cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         11972100  \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 64)                31872     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 12,004,492\n",
      "Trainable params: 32,392\n",
      "Non-trainable params: 11,972,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.initializers import Constant\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# define model\n",
    "gru_model = Sequential()\n",
    "e = Embedding(vocab_size, 100, embeddings_initializer=Constant(embedding_matrix), trainable=False)\n",
    "gru_model.add(e)\n",
    "gru_model.add(GRU(64, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "gru_model.add(Dense(8, activation='softmax'))\n",
    "# compile the model\n",
    "gru_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(gru_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e13226ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 00:06:08.728056: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2022-11-21 00:06:08.728115: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2022-11-21 00:06:08.728248: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs\n",
      "2022-11-21 00:06:08.731856: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory\n",
      "2022-11-21 00:06:08.732902: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so'; dlerror: libcupti.so: cannot open shared object file: No such file or directory\n",
      "2022-11-21 00:06:08.732973: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1661] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-11-21 00:06:08.733044: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2022-11-21 00:06:08.733111: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1752] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-11-21 00:06:14.270706: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-11-21 00:06:14.272282: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2095330000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 00:06:16.478165: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/704 [..............................] - ETA: 41:03 - loss: 2.1417 - accuracy: 0.0938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 00:06:17.654116: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-11-21 00:06:17.654205: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-11-21 00:06:17.970079: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2022-11-21 00:06:17.970128: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2022-11-21 00:06:17.970187: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1661] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  2/704 [..............................] - ETA: 4:32 - loss: 2.1201 - accuracy: 0.1211 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 00:06:18.228581: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-21 00:06:18.229197: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1752] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-11-21 00:06:18.402701: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-11-21 00:06:18.471690: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2022-11-21 00:06:18.511932: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/train/plugins/profile/2022_11_21_00_06_18\n",
      "2022-11-21 00:06:18.521183: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to logs/train/plugins/profile/2022_11_21_00_06_18/nasic02.trace.json.gz\n",
      "2022-11-21 00:06:18.677887: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/train/plugins/profile/2022_11_21_00_06_18\n",
      "2022-11-21 00:06:18.694877: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to logs/train/plugins/profile/2022_11_21_00_06_18/nasic02.memory_profile.json.gz\n",
      "2022-11-21 00:06:18.718276: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/train/plugins/profile/2022_11_21_00_06_18Dumped tool data for xplane.pb to logs/train/plugins/profile/2022_11_21_00_06_18/nasic02.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/train/plugins/profile/2022_11_21_00_06_18/nasic02.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/train/plugins/profile/2022_11_21_00_06_18/nasic02.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/train/plugins/profile/2022_11_21_00_06_18/nasic02.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/train/plugins/profile/2022_11_21_00_06_18/nasic02.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 130s 179ms/step - loss: 1.6421 - accuracy: 0.3952 - val_loss: 1.5314 - val_accuracy: 0.4410\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.53144, saving model to ./model_lstm/model_lstm_1.h5\n",
      "Epoch 2/10\n",
      "704/704 [==============================] - 127s 180ms/step - loss: 1.5276 - accuracy: 0.4398 - val_loss: 1.4949 - val_accuracy: 0.4560\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.53144 to 1.49492, saving model to ./model_lstm/model_lstm_2.h5\n",
      "Epoch 3/10\n",
      "704/704 [==============================] - 121s 171ms/step - loss: 1.4927 - accuracy: 0.4530 - val_loss: 1.4623 - val_accuracy: 0.4695\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.49492 to 1.46228, saving model to ./model_lstm/model_lstm_3.h5\n",
      "Epoch 4/10\n",
      "704/704 [==============================] - 125s 178ms/step - loss: 1.4677 - accuracy: 0.4644 - val_loss: 1.4419 - val_accuracy: 0.4746\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.46228 to 1.44192, saving model to ./model_lstm/model_lstm_4.h5\n",
      "Epoch 5/10\n",
      "704/704 [==============================] - 125s 178ms/step - loss: 1.4515 - accuracy: 0.4692 - val_loss: 1.4275 - val_accuracy: 0.4820\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.44192 to 1.42747, saving model to ./model_lstm/model_lstm_5.h5\n",
      "Epoch 6/10\n",
      "704/704 [==============================] - 126s 179ms/step - loss: 1.4378 - accuracy: 0.4751 - val_loss: 1.4172 - val_accuracy: 0.4860\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.42747 to 1.41719, saving model to ./model_lstm/model_lstm_6.h5\n",
      "Epoch 7/10\n",
      "704/704 [==============================] - 127s 180ms/step - loss: 1.4274 - accuracy: 0.4788 - val_loss: 1.4058 - val_accuracy: 0.4862\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.41719 to 1.40577, saving model to ./model_lstm/model_lstm_7.h5\n",
      "Epoch 8/10\n",
      "704/704 [==============================] - 126s 179ms/step - loss: 1.4168 - accuracy: 0.4834 - val_loss: 1.4016 - val_accuracy: 0.4886\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.40577 to 1.40163, saving model to ./model_lstm/model_lstm_8.h5\n",
      "Epoch 9/10\n",
      "704/704 [==============================] - 121s 172ms/step - loss: 1.4086 - accuracy: 0.4866 - val_loss: 1.3891 - val_accuracy: 0.4931\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.40163 to 1.38908, saving model to ./model_lstm/model_lstm_9.h5\n",
      "Epoch 10/10\n",
      "704/704 [==============================] - 124s 176ms/step - loss: 1.4030 - accuracy: 0.4888 - val_loss: 1.3880 - val_accuracy: 0.4932\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.38908 to 1.38805, saving model to ./model_lstm/model_lstm_10.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc523651710>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n",
    "csv_logger = CSVLogger('logs/training_log_lstm.csv')\n",
    "callbacks = [ModelCheckpoint(filepath='./model_lstm/model_lstm_{epoch}.h5', verbose=1, save_best_only=True), csv_logger, tensorboard_callback]\n",
    "\n",
    "# fit the model\n",
    "gru_model.fit(\n",
    "    review_pad, sentiment_oh, \n",
    "    batch_size=128, \n",
    "    epochs=10, \n",
    "    validation_split=0.1, \n",
    "    verbose=1, \n",
    "    callbacks=callbacks)\n",
    "# evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "883bc989",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f1742113",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2027), started 0:01:43 ago. (Use '!kill 2027' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-af252327fadd5a8b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-af252327fadd5a8b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8485aff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model_loads = keras.models.load_model('model_lstm/model_lstm_10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0d7d0fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_pad[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ca1547ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = gru_model.predict(review_pad[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "690e9732",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = label_decode(label_encoder, pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fd105200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_argmax = np.argmax(pc, axis=0)\n",
    "pc_argmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e36bca9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('testing accuracy: {}'.format(round(accuracy_score(label_decode(label_encoder, sentiment_oh[0:500]), pred_result), 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
