{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4b559c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax, BatchNormalization\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "825551c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14865930369712376671\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 19434962944\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13973157372185731690\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:02:00.0, compute capability: 8.6\"\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 01:33:24.802799: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-22 01:33:24.810484: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-22 01:33:24.828525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce RTX 3090 Ti computeCapability: 8.6\n",
      "coreClock: 1.905GHz coreCount: 84 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 938.86GiB/s\n",
      "2022-11-22 01:33:24.828576: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-11-22 01:33:24.903386: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-11-22 01:33:24.903485: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-11-22 01:33:24.930173: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-22 01:33:24.975262: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-22 01:33:25.010105: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-11-22 01:33:25.035478: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-11-22 01:33:25.036524: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-11-22 01:33:25.037571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-11-22 01:33:25.037659: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-11-22 01:33:25.838585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-11-22 01:33:25.838645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-11-22 01:33:25.838660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-11-22 01:33:25.839747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/device:GPU:0 with 18534 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:02:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8524757",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Data into pd dataframe\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "emotion_df = pd.read_csv('emotion.csv')\n",
    "di_df = pd.read_csv('data_identification.csv')\n",
    "sample_sub_df = pd.read_csv('sampleSubmission.csv')\n",
    "tweets_df = pd.read_pickle(\"tweets_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31411545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07ae829b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>[Sundayvibes]</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                hashtags  tweet_id  \\\n",
       "0                             [Snapchat]  0x376b20   \n",
       "1          [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "2                           [bibleverse]  0x28b412   \n",
       "3                                     []  0x1cd5b0   \n",
       "4                                     []  0x2de201   \n",
       "...                                  ...       ...   \n",
       "1867530  [mixedfeeling, butimTHATperson]  0x316b80   \n",
       "1867531                               []  0x29d0cb   \n",
       "1867532                               []  0x2a6a4f   \n",
       "1867533                               []  0x24faed   \n",
       "1867534                    [Sundayvibes]  0x34be8c   \n",
       "\n",
       "                                                      text  \n",
       "0        People who post \"add me on #Snapchat\" must be ...  \n",
       "1        @brianklaas As we see, Trump is dangerous to #...  \n",
       "2        Confident of your obedience, I write to you, k...  \n",
       "3                      Now ISSA is stalking Tasha 😂😂😂 <LH>  \n",
       "4        \"Trust is not the same as faith. A friend is s...  \n",
       "...                                                    ...  \n",
       "1867530  When you buy the last 2 tickets remaining for ...  \n",
       "1867531  I swear all this hard work gone pay off one da...  \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...  \n",
       "1867533  Ah, corporate life, where you can date <LH> us...  \n",
       "1867534             Blessed to be living #Sundayvibes <LH>  \n",
       "\n",
       "[1867535 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cefa1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[authentic, LaughOutLoud]</td>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455558</th>\n",
       "      <td>[NoWonder, Happy]</td>\n",
       "      <td>0x321566</td>\n",
       "      <td>I'm SO HAPPY!!! #NoWonder the name of this sho...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455559</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x38959e</td>\n",
       "      <td>In every circumtance I'd like to be thankful t...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455560</th>\n",
       "      <td>[blessyou]</td>\n",
       "      <td>0x2cbca6</td>\n",
       "      <td>there's currently two girls walking around the...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455561</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455562</th>\n",
       "      <td>[Sundayvibes]</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              hashtags  tweet_id  \\\n",
       "0                           [Snapchat]  0x376b20   \n",
       "1        [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "2                                   []  0x1cd5b0   \n",
       "3            [authentic, LaughOutLoud]  0x1d755c   \n",
       "4                                   []  0x2c91a8   \n",
       "...                                ...       ...   \n",
       "1455558              [NoWonder, Happy]  0x321566   \n",
       "1455559                             []  0x38959e   \n",
       "1455560                     [blessyou]  0x2cbca6   \n",
       "1455561                             []  0x24faed   \n",
       "1455562                  [Sundayvibes]  0x34be8c   \n",
       "\n",
       "                                                      text       emotion  \n",
       "0        People who post \"add me on #Snapchat\" must be ...  anticipation  \n",
       "1        @brianklaas As we see, Trump is dangerous to #...       sadness  \n",
       "2                      Now ISSA is stalking Tasha 😂😂😂 <LH>          fear  \n",
       "3        @RISKshow @TheKevinAllison Thx for the BEST TI...           joy  \n",
       "4             Still waiting on those supplies Liscus. <LH>  anticipation  \n",
       "...                                                    ...           ...  \n",
       "1455558  I'm SO HAPPY!!! #NoWonder the name of this sho...           joy  \n",
       "1455559  In every circumtance I'd like to be thankful t...           joy  \n",
       "1455560  there's currently two girls walking around the...           joy  \n",
       "1455561  Ah, corporate life, where you can date <LH> us...           joy  \n",
       "1455562             Blessed to be living #Sundayvibes <LH>           joy  \n",
       "\n",
       "[1455563 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data = pd.merge(tweets_df, emotion_df)\n",
    "t_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72fc1552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41563</th>\n",
       "      <td>[RanbirKapoor]</td>\n",
       "      <td>0x2db88f</td>\n",
       "      <td>T834: I don't know why bad things are more hap...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374274</th>\n",
       "      <td>[GameOfThones7, Insecure]</td>\n",
       "      <td>0x2912a4</td>\n",
       "      <td>So I watched yesterday's episode of #GameOfTho...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145835</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x34f07c</td>\n",
       "      <td>What is it with dokkan on Apple I get better p...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440919</th>\n",
       "      <td>[XtraXtraLove, MercyChinwo]</td>\n",
       "      <td>0x376008</td>\n",
       "      <td>Excess love. Your love is kind, Your love is p...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420229</th>\n",
       "      <td>[prochoice, Safe, OnDemandNoApologies, Governm...</td>\n",
       "      <td>0x232989</td>\n",
       "      <td>As fast as #prochoice went from #Safe&amp;Rare to ...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489632</th>\n",
       "      <td>[WOKENWisdom]</td>\n",
       "      <td>0x2cf73c</td>\n",
       "      <td>@MATTHARDYBRAND Can your #WOKENWisdom explain ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912367</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1d4175</td>\n",
       "      <td>PrankInvasion CALLS OUT h3h3Productions |  &lt;LH...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181239</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1f8e7d</td>\n",
       "      <td>@pamera_chen &lt;LH&gt; WIFEY💗</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602382</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x352a65</td>\n",
       "      <td>We are creatures of habit. Praising &lt;LH&gt; is ha...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879610</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2b1936</td>\n",
       "      <td>Mr.President @realDonaldTrump Nothing in world...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  hashtags  tweet_id  \\\n",
       "41563                                       [RanbirKapoor]  0x2db88f   \n",
       "1374274                          [GameOfThones7, Insecure]  0x2912a4   \n",
       "1145835                                                 []  0x34f07c   \n",
       "440919                         [XtraXtraLove, MercyChinwo]  0x376008   \n",
       "1420229  [prochoice, Safe, OnDemandNoApologies, Governm...  0x232989   \n",
       "...                                                    ...       ...   \n",
       "489632                                       [WOKENWisdom]  0x2cf73c   \n",
       "912367                                                  []  0x1d4175   \n",
       "1181239                                                 []  0x1f8e7d   \n",
       "602382                                                  []  0x352a65   \n",
       "879610                                                  []  0x2b1936   \n",
       "\n",
       "                                                      text       emotion  \n",
       "41563    T834: I don't know why bad things are more hap...           joy  \n",
       "1374274  So I watched yesterday's episode of #GameOfTho...          fear  \n",
       "1145835  What is it with dokkan on Apple I get better p...       disgust  \n",
       "440919   Excess love. Your love is kind, Your love is p...         trust  \n",
       "1420229  As fast as #prochoice went from #Safe&Rare to ...         trust  \n",
       "...                                                    ...           ...  \n",
       "489632   @MATTHARDYBRAND Can your #WOKENWisdom explain ...       sadness  \n",
       "912367   PrankInvasion CALLS OUT h3h3Productions |  <LH...      surprise  \n",
       "1181239                           @pamera_chen <LH> WIFEY💗           joy  \n",
       "602382   We are creatures of habit. Praising <LH> is ha...  anticipation  \n",
       "879610   Mr.President @realDonaldTrump Nothing in world...  anticipation  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data_sample = t_data.sample(n=100)\n",
    "t_data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcadeef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.2.0/en_core_web_md-3.2.0-py3-none-any.whl (45.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.7/45.7 MB 10.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from en-core-web-md==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.1.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.19.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.28.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.4.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.3)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.8.1)\n",
      "Requirement already satisfied: setuptools in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (65.5.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.4.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (4.64.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2022.9.24)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (5.0.0)\n",
      "Installing collected packages: en-core-web-md\n",
      "  Attempting uninstall: en-core-web-md\n",
      "    Found existing installation: en-core-web-md 3.3.0\n",
      "    Uninstalling en-core-web-md-3.3.0:\n",
      "      Successfully uninstalled en-core-web-md-3.3.0\n",
      "Successfully installed en-core-web-md-3.2.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import spacy.cli\n",
    "\n",
    "spacy.cli.download(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2a26fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md', disable=[\"ner\", \"parser\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bd362a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Apple  --> Apple\n",
      "Word: is  --> be\n",
      "Word: looking  --> look\n",
      "Word: at  --> at\n",
      "Word: buying  --> buy\n",
      "Word: U.K.  --> U.K.\n",
      "Word: startup  --> startup\n",
      "Word: for  --> for\n",
      "Word: $  --> $\n",
      "Word: 1  --> 1\n",
      "Word: billion  --> billion\n"
     ]
    }
   ],
   "source": [
    "for token in  nlp(\"Apple is looking at buying U.K. startup for $1 billion\"):\n",
    "  print('Word: {}  --> {}'.format(token.text, token.lemma_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc4d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"wiki-lemma-100D-phrase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14f108fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Microsoft', 0.8559668660163879),\n",
       " ('Google_Search', 0.8424477577209473),\n",
       " ('Google_Analytics', 0.8412379026412964),\n",
       " ('Yahoo', 0.8326561450958252),\n",
       " ('AltaVista', 0.824895977973938)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('Google', topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74523046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# # Get all words from wiki word2vec model\n",
    "# model_words = set(model.wv.index_to_key)\n",
    "\n",
    "# def text2vec_raw(w2vmodel, text):\n",
    "#     doc = nlp(text)\n",
    "#     # convert a movie review into vectors\n",
    "#     text_vecs = [w2vmodel.wv[word.lemma_] for word in doc if word.lemma_ in model_words]\n",
    "#     # calculate the mean of the vectors and return\n",
    "\n",
    "#     if len(text_vecs) > 1:\n",
    "#         res =  np.mean(text_vecs, axis = 0)\n",
    "#         return res\n",
    "#     elif len(text_vecs) == 1:\n",
    "#         return text_vecs[0]\n",
    "#     else:\n",
    "#         return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e27b4088",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('keras_word2vec.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5398684a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['346848', '100']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "with open('keras_word2vec.txt') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    # 只接受長度為 101 的向量 (word + 100d embedding)\n",
    "    if len(values) != 101:\n",
    "      print(values)\n",
    "      continue\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69f2869a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.2.0/en_core_web_md-3.2.0-py3-none-any.whl (45.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.7/45.7 MB 4.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from en-core-web-md==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.28.1)\n",
      "Requirement already satisfied: jinja2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.19.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (21.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (4.64.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: setuptools in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (65.5.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.26.12)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (5.0.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 236.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_md\")\n",
    "nlp = spacy.load('en_core_web_md', disable=[\"ner\", \"parser\"])\n",
    "\n",
    "review_lines = list()\n",
    "reviews = t_data_sample['text'].values.tolist()\n",
    "\n",
    "for review in tqdm(reviews):   \n",
    "    doc = nlp(review)\n",
    "    words = [word.lemma_ for word in doc]\n",
    "    review_lines.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "806f7d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "np.save(\"test_review_lines\", review_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c8ccfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review_lines = np.load(\"test_review_lines.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "554917f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'sadness', 'fear', ..., 'joy', 'joy', 'joy'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = t_data['emotion'].values\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df72ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(review_lines, t_data_sample['emotion'],\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.25, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01324210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  75000\n",
      "y_train.shape:  (75000,)\n",
      "x_test.shape:  25000\n",
      "y_test.shape:  (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape: \", len(X_train))\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"x_test.shape: \", len(X_test))\n",
    "print(\"y_test.shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "895456e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  ['anger' 'anticipation' 'disgust' 'fear' 'joy' 'sadness' 'surprise'\n",
      " 'trust']\n",
      "\n",
      "## Before convert\n",
      "y_train[0:4]:\n",
      " ['anticipation' 'sadness' 'fear' 'joy']\n",
      "\n",
      "y_train.shape:  (1455563,)\n",
      "\n",
      "\n",
      "## After convert\n",
      "y_train[0:4]:\n",
      " [[0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      "y_train.shape:  (1455563, 8)\n"
     ]
    }
   ],
   "source": [
    "## deal with label (string -> one-hot)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(sentiment)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:4]:\\n', sentiment[0:4])\n",
    "print('\\ny_train.shape: ', sentiment.shape)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return np_utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "sentiment_oh = label_encode(label_encoder, sentiment)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:4]:\\n', sentiment_oh[0:4])\n",
    "print('\\ny_train.shape: ', sentiment_oh.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3dfe64d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimal word count in a movie review:  1\n",
      "The first quantile (25%) of word count in a movie review: 10.0\n",
      "The second quantile (50%) of word count in a movie review: 15.0\n",
      "The third quantile (75%) of word count in a movie review: 20.0\n",
      "The maximum word count in a movie review:  43\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "### 找出影評共有幾個 words\n",
    "sentence_lengths = t_data_sample['text'].apply(lambda x: len(x.split()))\n",
    "quantiles = np.percentile(sentence_lengths, [25, 50, 75])\n",
    "\n",
    "print('The minimal word count in a movie review: ', min(sentence_lengths))\n",
    "print('The first quantile (25%) of word count in a movie review:', quantiles[0])\n",
    "print('The second quantile (50%) of word count in a movie review:', quantiles[1])\n",
    "print('The third quantile (75%) of word count in a movie review:', quantiles[2])\n",
    "print('The maximum word count in a movie review: ', max(sentence_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2ff6709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 119720 unique tokens.\n",
      "Shape of review tensor: (100000, 50)\n",
      "Shape of sentiment tensor: (100000, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 初始化 tokenizer\n",
    "# 將文字轉換成 2D integer tensor\n",
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(review_lines)\n",
    "sequences = tokenizer_obj.texts_to_sequences(review_lines)\n",
    "\n",
    "# 因為model的input必須一樣長，所以要使用padding，句子短於512的都會補0，長於512的會被truncate\n",
    "word_index = tokenizer_obj.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "review_pad = pad_sequences(sequences, maxlen=50)\n",
    "\n",
    "print('Shape of review tensor:', review_pad.shape)\n",
    "print('Shape of sentiment tensor:', sentiment_oh.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1f107501",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in tokenizer_obj.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28ea5cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         11972100  \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 64)                31872     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 12,004,492\n",
      "Trainable params: 32,392\n",
      "Non-trainable params: 11,972,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.initializers import Constant\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# define model\n",
    "gru_model = Sequential()\n",
    "e = Embedding(vocab_size, 100, embeddings_initializer=Constant(embedding_matrix), trainable=False)\n",
    "gru_model.add(e)\n",
    "gru_model.add(GRU(64, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "gru_model.add(Dense(8, activation='softmax'))\n",
    "# compile the model\n",
    "gru_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(gru_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e13226ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 00:06:08.728056: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2022-11-21 00:06:08.728115: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2022-11-21 00:06:08.728248: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs\n",
      "2022-11-21 00:06:08.731856: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory\n",
      "2022-11-21 00:06:08.732902: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so'; dlerror: libcupti.so: cannot open shared object file: No such file or directory\n",
      "2022-11-21 00:06:08.732973: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1661] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-11-21 00:06:08.733044: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2022-11-21 00:06:08.733111: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1752] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-11-21 00:06:14.270706: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-11-21 00:06:14.272282: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2095330000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 00:06:16.478165: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/704 [..............................] - ETA: 41:03 - loss: 2.1417 - accuracy: 0.0938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 00:06:17.654116: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-11-21 00:06:17.654205: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-11-21 00:06:17.970079: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2022-11-21 00:06:17.970128: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2022-11-21 00:06:17.970187: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1661] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  2/704 [..............................] - ETA: 4:32 - loss: 2.1201 - accuracy: 0.1211 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 00:06:18.228581: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-11-21 00:06:18.229197: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1752] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2022-11-21 00:06:18.402701: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-11-21 00:06:18.471690: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2022-11-21 00:06:18.511932: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/train/plugins/profile/2022_11_21_00_06_18\n",
      "2022-11-21 00:06:18.521183: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to logs/train/plugins/profile/2022_11_21_00_06_18/nasic02.trace.json.gz\n",
      "2022-11-21 00:06:18.677887: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: logs/train/plugins/profile/2022_11_21_00_06_18\n",
      "2022-11-21 00:06:18.694877: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to logs/train/plugins/profile/2022_11_21_00_06_18/nasic02.memory_profile.json.gz\n",
      "2022-11-21 00:06:18.718276: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/train/plugins/profile/2022_11_21_00_06_18Dumped tool data for xplane.pb to logs/train/plugins/profile/2022_11_21_00_06_18/nasic02.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/train/plugins/profile/2022_11_21_00_06_18/nasic02.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/train/plugins/profile/2022_11_21_00_06_18/nasic02.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/train/plugins/profile/2022_11_21_00_06_18/nasic02.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/train/plugins/profile/2022_11_21_00_06_18/nasic02.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704/704 [==============================] - 130s 179ms/step - loss: 1.6421 - accuracy: 0.3952 - val_loss: 1.5314 - val_accuracy: 0.4410\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.53144, saving model to ./model_lstm/model_lstm_1.h5\n",
      "Epoch 2/10\n",
      "704/704 [==============================] - 127s 180ms/step - loss: 1.5276 - accuracy: 0.4398 - val_loss: 1.4949 - val_accuracy: 0.4560\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.53144 to 1.49492, saving model to ./model_lstm/model_lstm_2.h5\n",
      "Epoch 3/10\n",
      "704/704 [==============================] - 121s 171ms/step - loss: 1.4927 - accuracy: 0.4530 - val_loss: 1.4623 - val_accuracy: 0.4695\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.49492 to 1.46228, saving model to ./model_lstm/model_lstm_3.h5\n",
      "Epoch 4/10\n",
      "704/704 [==============================] - 125s 178ms/step - loss: 1.4677 - accuracy: 0.4644 - val_loss: 1.4419 - val_accuracy: 0.4746\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.46228 to 1.44192, saving model to ./model_lstm/model_lstm_4.h5\n",
      "Epoch 5/10\n",
      "704/704 [==============================] - 125s 178ms/step - loss: 1.4515 - accuracy: 0.4692 - val_loss: 1.4275 - val_accuracy: 0.4820\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.44192 to 1.42747, saving model to ./model_lstm/model_lstm_5.h5\n",
      "Epoch 6/10\n",
      "704/704 [==============================] - 126s 179ms/step - loss: 1.4378 - accuracy: 0.4751 - val_loss: 1.4172 - val_accuracy: 0.4860\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.42747 to 1.41719, saving model to ./model_lstm/model_lstm_6.h5\n",
      "Epoch 7/10\n",
      "704/704 [==============================] - 127s 180ms/step - loss: 1.4274 - accuracy: 0.4788 - val_loss: 1.4058 - val_accuracy: 0.4862\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.41719 to 1.40577, saving model to ./model_lstm/model_lstm_7.h5\n",
      "Epoch 8/10\n",
      "704/704 [==============================] - 126s 179ms/step - loss: 1.4168 - accuracy: 0.4834 - val_loss: 1.4016 - val_accuracy: 0.4886\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.40577 to 1.40163, saving model to ./model_lstm/model_lstm_8.h5\n",
      "Epoch 9/10\n",
      "704/704 [==============================] - 121s 172ms/step - loss: 1.4086 - accuracy: 0.4866 - val_loss: 1.3891 - val_accuracy: 0.4931\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.40163 to 1.38908, saving model to ./model_lstm/model_lstm_9.h5\n",
      "Epoch 10/10\n",
      "704/704 [==============================] - 124s 176ms/step - loss: 1.4030 - accuracy: 0.4888 - val_loss: 1.3880 - val_accuracy: 0.4932\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.38908 to 1.38805, saving model to ./model_lstm/model_lstm_10.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc523651710>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n",
    "csv_logger = CSVLogger('logs/training_log_lstm.csv')\n",
    "callbacks = [ModelCheckpoint(filepath='./model_lstm/model_lstm_{epoch}.h5', verbose=1, save_best_only=True), csv_logger, tensorboard_callback]\n",
    "\n",
    "# fit the model\n",
    "gru_model.fit(\n",
    "    review_pad, sentiment_oh, \n",
    "    batch_size=128, \n",
    "    epochs=10, \n",
    "    validation_split=0.1, \n",
    "    verbose=1, \n",
    "    callbacks=callbacks)\n",
    "# evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "883bc989",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f1742113",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2027), started 0:01:43 ago. (Use '!kill 2027' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-af252327fadd5a8b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-af252327fadd5a8b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8485aff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 01:34:05.986771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce RTX 3090 Ti computeCapability: 8.6\n",
      "coreClock: 1.905GHz coreCount: 84 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 938.86GiB/s\n",
      "2022-11-22 01:34:05.987518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-11-22 01:34:05.988428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce RTX 3090 Ti computeCapability: 8.6\n",
      "coreClock: 1.905GHz coreCount: 84 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 938.86GiB/s\n",
      "2022-11-22 01:34:05.989093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-11-22 01:34:05.989158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-11-22 01:34:05.989176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-11-22 01:34:05.989191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-11-22 01:34:05.989981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 18534 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:02:00.0, compute capability: 8.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model_loads = keras.models.load_model('model_lstm/model_lstm_10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0d7d0fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_pad[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ca1547ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = gru_model.predict(review_pad[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "690e9732",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = label_decode(label_encoder, pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fd105200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_argmax = np.argmax(pc, axis=0)\n",
    "pc_argmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e36bca9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('testing accuracy: {}'.format(round(accuracy_score(label_decode(label_encoder, sentiment_oh[0:500]), pred_result), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28de4d45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x29e452</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x227e25</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x293813</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x1e1a7e</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x2156a5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x2bb9d2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id identification\n",
       "0        0x28cc61           test\n",
       "1        0x29e452          train\n",
       "2        0x2b3819          train\n",
       "3        0x2db41f           test\n",
       "4        0x2a2acc          train\n",
       "...           ...            ...\n",
       "1867530  0x227e25          train\n",
       "1867531  0x293813          train\n",
       "1867532  0x1e1a7e          train\n",
       "1867533  0x2156a5          train\n",
       "1867534  0x2bb9d2          train\n",
       "\n",
       "[1867535 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2477759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0x2466f6</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0x23f9e9</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0x1fb4e1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867495</th>\n",
       "      <td>0x2c4dc2</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867496</th>\n",
       "      <td>0x31be7c</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867500</th>\n",
       "      <td>0x1ca58e</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867515</th>\n",
       "      <td>0x35c8ba</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867518</th>\n",
       "      <td>0x1d941b</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id identification\n",
       "0        0x28cc61           test\n",
       "3        0x2db41f           test\n",
       "15       0x2466f6           test\n",
       "23       0x23f9e9           test\n",
       "31       0x1fb4e1           test\n",
       "...           ...            ...\n",
       "1867495  0x2c4dc2           test\n",
       "1867496  0x31be7c           test\n",
       "1867500  0x1ca58e           test\n",
       "1867515  0x35c8ba           test\n",
       "1867518  0x1d941b           test\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di_df[di_df['identification'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e676739a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[materialism, money, possessions]</td>\n",
       "      <td>0x218443</td>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[GodsPlan, GodsWork]</td>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x26289a</td>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>\"For this is the message that ye heard from th...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>\"There is a lad here, which hath five barley l...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 hashtags  tweet_id  \\\n",
       "0                            [bibleverse]  0x28b412   \n",
       "1                                      []  0x2de201   \n",
       "2       [materialism, money, possessions]  0x218443   \n",
       "3                    [GodsPlan, GodsWork]  0x2939d5   \n",
       "4                                      []  0x26289a   \n",
       "...                                   ...       ...   \n",
       "411967                                 []  0x2913b4   \n",
       "411968                                 []  0x2a980e   \n",
       "411969    [mixedfeeling, butimTHATperson]  0x316b80   \n",
       "411970                                 []  0x29d0cb   \n",
       "411971                                 []  0x2a6a4f   \n",
       "\n",
       "                                                     text identification  \n",
       "0       Confident of your obedience, I write to you, k...           test  \n",
       "1       \"Trust is not the same as faith. A friend is s...           test  \n",
       "2       When do you have enough ? When are you satisfi...           test  \n",
       "3       God woke you up, now chase the day #GodsPlan #...           test  \n",
       "4       In these tough times, who do YOU turn to as yo...           test  \n",
       "...                                                   ...            ...  \n",
       "411967  \"For this is the message that ye heard from th...           test  \n",
       "411968  \"There is a lad here, which hath five barley l...           test  \n",
       "411969  When you buy the last 2 tickets remaining for ...           test  \n",
       "411970  I swear all this hard work gone pay off one da...           test  \n",
       "411971  @Parcel2Go no card left when I wasn't in so I ...           test  \n",
       "\n",
       "[411972 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_test_df = pd.merge(tweets_df, di_df[di_df['identification'] == 'test'])\n",
    "tweets_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c2f3733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>[Sundayvibes]</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                hashtags  tweet_id  \\\n",
       "0                             [Snapchat]  0x376b20   \n",
       "1          [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "2                           [bibleverse]  0x28b412   \n",
       "3                                     []  0x1cd5b0   \n",
       "4                                     []  0x2de201   \n",
       "...                                  ...       ...   \n",
       "1867530  [mixedfeeling, butimTHATperson]  0x316b80   \n",
       "1867531                               []  0x29d0cb   \n",
       "1867532                               []  0x2a6a4f   \n",
       "1867533                               []  0x24faed   \n",
       "1867534                    [Sundayvibes]  0x34be8c   \n",
       "\n",
       "                                                      text  \n",
       "0        People who post \"add me on #Snapchat\" must be ...  \n",
       "1        @brianklaas As we see, Trump is dangerous to #...  \n",
       "2        Confident of your obedience, I write to you, k...  \n",
       "3                      Now ISSA is stalking Tasha 😂😂😂 <LH>  \n",
       "4        \"Trust is not the same as faith. A friend is s...  \n",
       "...                                                    ...  \n",
       "1867530  When you buy the last 2 tickets remaining for ...  \n",
       "1867531  I swear all this hard work gone pay off one da...  \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...  \n",
       "1867533  Ah, corporate life, where you can date <LH> us...  \n",
       "1867534             Blessed to be living #Sundayvibes <LH>  \n",
       "\n",
       "[1867535 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67d6c629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x2c7743</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2c1eed</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2826ea</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x356d9a</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x20fd95</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x351857</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x2c028e</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x1f2430</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x2be24e</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x35802a</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id   emotion\n",
       "0       0x2c7743  surprise\n",
       "1       0x2c1eed  surprise\n",
       "2       0x2826ea  surprise\n",
       "3       0x356d9a  surprise\n",
       "4       0x20fd95  surprise\n",
       "...          ...       ...\n",
       "411967  0x351857  surprise\n",
       "411968  0x2c028e  surprise\n",
       "411969  0x1f2430  surprise\n",
       "411970  0x2be24e  surprise\n",
       "411971  0x35802a  surprise\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "956217c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.2.0/en_core_web_md-3.2.0-py3-none-any.whl (45.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.7/45.7 MB 11.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from en-core-web-md==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: setuptools in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (65.5.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.19.2)\n",
      "Requirement already satisfied: jinja2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.4.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.4.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.8)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.10.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.28.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (0.8.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (4.64.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (21.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2022.9.24)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-md==3.2.0) (5.0.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 411972/411972 [25:23<00:00, 270.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_md\")\n",
    "nlp = spacy.load('en_core_web_md', disable=[\"ner\", \"parser\"])\n",
    "\n",
    "review_lines_test = list()\n",
    "reviews = tweets_test_df['text'].values.tolist()\n",
    "\n",
    "for review in tqdm(reviews):   \n",
    "    doc = nlp(review)\n",
    "    words = [word.lemma_ for word in doc]\n",
    "    review_lines_test.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1c3b7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "np.save(\"review_lines_test\", review_lines_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cdc31d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "review_lines_test = np.load(\"review_lines_test.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a40e0740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model_loads = keras.models.load_model('model_lstm/model_lstm_10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9feb974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 299043 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 初始化 tokenizer\n",
    "# 將文字轉換成 2D integer tensor\n",
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(review_lines_test)\n",
    "sequences = tokenizer_obj.texts_to_sequences(review_lines_test)\n",
    "\n",
    "# 因為model的input必須一樣長，所以要使用padding，句子短於512的都會補0，長於512的會被truncate\n",
    "word_index = tokenizer_obj.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "review_pad_test = pad_sequences(sequences, maxlen=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a5e1ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['confident',\n",
       " 'of',\n",
       " 'your',\n",
       " 'obedience',\n",
       " ',',\n",
       " 'I',\n",
       " 'write',\n",
       " 'to',\n",
       " 'you',\n",
       " ',',\n",
       " 'know',\n",
       " 'that',\n",
       " 'you',\n",
       " 'will',\n",
       " 'do',\n",
       " 'even',\n",
       " 'more',\n",
       " 'than',\n",
       " 'I',\n",
       " 'ask',\n",
       " '.',\n",
       " '(',\n",
       " 'Philemon',\n",
       " '1:21',\n",
       " ')',\n",
       " '3/4',\n",
       " '#',\n",
       " 'bibleverse',\n",
       " '<',\n",
       " 'LH',\n",
       " '>',\n",
       " '<',\n",
       " 'LH',\n",
       " '>']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_lines_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23c0c6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2780,\n",
       "  18,\n",
       "  32,\n",
       "  4584,\n",
       "  11,\n",
       "  6,\n",
       "  401,\n",
       "  9,\n",
       "  14,\n",
       "  11,\n",
       "  63,\n",
       "  25,\n",
       "  14,\n",
       "  54,\n",
       "  22,\n",
       "  110,\n",
       "  89,\n",
       "  114,\n",
       "  6,\n",
       "  189,\n",
       "  5,\n",
       "  172,\n",
       "  40045,\n",
       "  13173,\n",
       "  161,\n",
       "  5182,\n",
       "  7,\n",
       "  6185,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  3]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_obj.texts_to_sequences([review_lines_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a1afd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,  2780,    18,\n",
       "          32,  4584,    11,     6,   401,     9,    14,    11,    63,\n",
       "          25,    14,    54,    22,   110,    89,   114,     6,   189,\n",
       "           5,   172, 40045, 13173,   161,  5182,     7,  6185,     2,\n",
       "           1,     3,     2,     1,     3], dtype=int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_pad_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf239566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of review tensor: (411972, 50)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of review tensor:', review_pad_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4833ff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 01:37:03.065166: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-11-22 01:37:03.066061: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2095330000 Hz\n",
      "2022-11-22 01:37:15.246649: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8/12875 [..............................] - ETA: 5:30"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 01:37:16.424496: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-11-22 01:37:16.424580: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2234/12875 [====>.........................] - ETA: 4:44"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument:  indices[18,29] = 119738 is not in [0, 119721)\n\t [[node sequential_1/embedding_1/embedding_lookup (defined at home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/keras/layers/embeddings.py:184) ]]\n  (1) Invalid argument:  indices[18,29] = 119738 is not in [0, 119721)\n\t [[node sequential_1/embedding_1/embedding_lookup (defined at home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/keras/layers/embeddings.py:184) ]]\n\t [[sequential_1/embedding_1/embedding_lookup/_9]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_predict_function_1321]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_1/embedding_1/embedding_lookup:\n sequential_1/embedding_1/Cast (defined at home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/keras/layers/embeddings.py:183)\t\n sequential_1/embedding_1/embedding_lookup/1024 (defined at home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/contextlib.py:112)\n\nInput Source operations connected to node sequential_1/embedding_1/embedding_lookup:\n sequential_1/embedding_1/Cast (defined at home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/keras/layers/embeddings.py:183)\t\n sequential_1/embedding_1/embedding_lookup/1024 (defined at home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/contextlib.py:112)\n\nFunction call stack:\npredict_function -> predict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29998/3978767117.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_loads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_pad_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1700\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  indices[18,29] = 119738 is not in [0, 119721)\n\t [[node sequential_1/embedding_1/embedding_lookup (defined at home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/keras/layers/embeddings.py:184) ]]\n  (1) Invalid argument:  indices[18,29] = 119738 is not in [0, 119721)\n\t [[node sequential_1/embedding_1/embedding_lookup (defined at home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/keras/layers/embeddings.py:184) ]]\n\t [[sequential_1/embedding_1/embedding_lookup/_9]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_predict_function_1321]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_1/embedding_1/embedding_lookup:\n sequential_1/embedding_1/Cast (defined at home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/keras/layers/embeddings.py:183)\t\n sequential_1/embedding_1/embedding_lookup/1024 (defined at home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/contextlib.py:112)\n\nInput Source operations connected to node sequential_1/embedding_1/embedding_lookup:\n sequential_1/embedding_1/Cast (defined at home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/site-packages/keras/layers/embeddings.py:183)\t\n sequential_1/embedding_1/embedding_lookup/1024 (defined at home/eric/anaconda3/envs/dm_tf_2.5_py_3.7_spacy/lib/python3.7/contextlib.py:112)\n\nFunction call stack:\npredict_function -> predict_function\n"
     ]
    }
   ],
   "source": [
    "predict = model_loads.predict(review_pad_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f47ca6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411972, 8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edfbcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = label_decode(label_encoder, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11710ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411972,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e304ae3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['trust', 'joy', 'joy', ..., 'joy', 'sadness', 'joy'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da463d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test_df['emotion'] = pred_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b06b06b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>test</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>test</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[materialism, money, possessions]</td>\n",
       "      <td>0x218443</td>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "      <td>test</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[GodsPlan, GodsWork]</td>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "      <td>test</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x26289a</td>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "      <td>test</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>\"For this is the message that ye heard from th...</td>\n",
       "      <td>test</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>\"There is a lad here, which hath five barley l...</td>\n",
       "      <td>test</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>test</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>test</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>test</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 hashtags  tweet_id  \\\n",
       "0                            [bibleverse]  0x28b412   \n",
       "1                                      []  0x2de201   \n",
       "2       [materialism, money, possessions]  0x218443   \n",
       "3                    [GodsPlan, GodsWork]  0x2939d5   \n",
       "4                                      []  0x26289a   \n",
       "...                                   ...       ...   \n",
       "411967                                 []  0x2913b4   \n",
       "411968                                 []  0x2a980e   \n",
       "411969    [mixedfeeling, butimTHATperson]  0x316b80   \n",
       "411970                                 []  0x29d0cb   \n",
       "411971                                 []  0x2a6a4f   \n",
       "\n",
       "                                                     text identification  \\\n",
       "0       Confident of your obedience, I write to you, k...           test   \n",
       "1       \"Trust is not the same as faith. A friend is s...           test   \n",
       "2       When do you have enough ? When are you satisfi...           test   \n",
       "3       God woke you up, now chase the day #GodsPlan #...           test   \n",
       "4       In these tough times, who do YOU turn to as yo...           test   \n",
       "...                                                   ...            ...   \n",
       "411967  \"For this is the message that ye heard from th...           test   \n",
       "411968  \"There is a lad here, which hath five barley l...           test   \n",
       "411969  When you buy the last 2 tickets remaining for ...           test   \n",
       "411970  I swear all this hard work gone pay off one da...           test   \n",
       "411971  @Parcel2Go no card left when I wasn't in so I ...           test   \n",
       "\n",
       "        emotion  \n",
       "0         trust  \n",
       "1           joy  \n",
       "2           joy  \n",
       "3       disgust  \n",
       "4       sadness  \n",
       "...         ...  \n",
       "411967      joy  \n",
       "411968      joy  \n",
       "411969      joy  \n",
       "411970  sadness  \n",
       "411971      joy  \n",
       "\n",
       "[411972 rows x 5 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee8ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submit = tweets_test_df[['tweet_id', 'emotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "157d8c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_id  emotion\n",
       "0       0x28b412    trust\n",
       "1       0x2de201      joy\n",
       "2       0x218443      joy\n",
       "3       0x2939d5  disgust\n",
       "4       0x26289a  sadness\n",
       "...          ...      ...\n",
       "411967  0x2913b4      joy\n",
       "411968  0x2a980e      joy\n",
       "411969  0x316b80      joy\n",
       "411970  0x29d0cb  sadness\n",
       "411971  0x2a6a4f      joy\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab93049",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submit_2 = output_submit.rename(columns = {'tweet_id':'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "94276c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  emotion\n",
       "0       0x28b412    trust\n",
       "1       0x2de201      joy\n",
       "2       0x218443      joy\n",
       "3       0x2939d5  disgust\n",
       "4       0x26289a  sadness\n",
       "...          ...      ...\n",
       "411967  0x2913b4      joy\n",
       "411968  0x2a980e      joy\n",
       "411969  0x316b80      joy\n",
       "411970  0x29d0cb  sadness\n",
       "411971  0x2a6a4f      joy\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_submit_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8393d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submit_2.to_csv('output_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
